---
title: Publications
layout: default
permalink: /publications/
---

# Publications
        
<p> TBD </p>


<!DOCTYPE html>
<html lang="en-us">

<header role="banner">
  <head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>
    
      Papers &middot; Nikhil Garg
    
  </title>
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
  <link href='https://fonts.googleapis.com/css?family=Open Sans Condensed' rel='stylesheet'>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <link rel="stylesheet" href="/public/css/own.css">
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
</head>

</header>

  <body>
     <script>0</script> <!-- Apparently removes flash without stylying in firefox -->
    <div class="sidebar">
  <div class="container sidebar">
    <center>
      <h1>
        <font color="WHITESMOKE" margin-top="0rem"> Nikhil Garg </font>
      </h1>
      <div class="sidebar-about">
        <img src="/img/garg_headshot.webp" style="round" width="300" id="circle" alt="headshot">
        <div class="externalicons"><a href="mailto:nkgar6@gmail.com" title="Email"><i class="fa fa-envelope"></i></a>
        </div>
        <!-- <div class="externalicons"><a href="https://medium.com/@nikhil_garg" title="Medium"><i
              class="fa fa-medium"></i></a></div> -->
        <div class="externalicons"><a href="https://twitter.com/NikhGarg" style="margin-right:0px;" title="Twitter"><i
              class="fa fa-twitter"></i></a></div>
        <div class="smallpagebreak"></div>
        <div class="externalicons"><a href="https://github.com/nikhgarg/" title="Github"><i
              class="fa fa-github"></i></a></div>
        <div class="externalicons"><a href="https://scholar.google.com/citations?user=8qSK3noAAAAJ&hl=en"
            title="Google Scholar"><i class="ai ai-google-scholar"></i></a></div>
        <div class="externalicons"><a href="/files/GargNikhilCV.pdf" title="CV"><i style="margin-right:0px;"
              class="ai ai-cv"></i></a></div>
      </div>
    </center>
    <br>
    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">Home</a>
      <a class="sidebar-nav-item" href="/Papers/">Papers</a>
      <a class="sidebar-nav-item" href="/Teaching/">Teaching</a>
      <a class="sidebar-nav-item" href="/ResearchGroup/">Group</a>
      <a class="sidebar-nav-item" href="/Blog">Blog</a>
    </nav>
  </div>
</div>

    <main role="main">
    <div class="content container">
      <div class="page">
  <script type="text/javascript" src="/public/scripts.js"></script>

<body onload="openPapers(event, 'PaperType');">

<style>
p.smallbib {
    line-height: 1.3;
    font-size:1em;
}
</style>

<style>
p.reallysmallbib {
    line-height: 1.3;
    font-size:1em;
}
</style>

<h1 class="page-title" style="display:inline;">Papers</h1>

<div class="tab">
  <button class="tablinks active" id="PaperTypeButton" onclick="openPapers(event, 'PaperType')">By Paper Type</button>
  <button class="tablinks" id="ChronologicalButton" onclick="openPapers(event, 'Chronological')">Chronological</button>
  <!-- <button class="tablinks" id="TopicButton" onclick="openPapers(event, 'Topic')">By Topic</button> -->
</div>

<p>
See also <a href="https://scholar.google.com/citations?user=8qSK3noAAAAJ&hl=en" title="Google Scholar">Google Scholar.</a>
</p>

<div id="PaperType" class="tabcontent">
  
  
    
    
    <h2> Working Papers</h2>
    <ol class="bibliography"><li><p class="reallysmallbib">
<strong>Optimal Strategies in Ranked-Choice Voting</strong>





[<a href="javascript:;"onclick=showdropinfo('deshpandestrategies24abstract')>abstract</a> | <a href="https://arxiv.org/abs/2407.13661">arxiv</a>]

<script>
  coloryear("deshpandestrategies24", 2050, 2024);
</script>

<br><span id="deshpandestrategies24">Sanyukta Deshpande, Nikhil Garg, and Sheldon Jacobson</span> <br>
 
 


<div id='deshpandestrategies24abstract'  class="abstractcollapsed">Ranked Choice Voting (RCV) and Single Transferable Voting (STV) are widely valued; but are complex to understand due to intricate per-round vote transfers. Questions like determining how far a candidate is from winning or identifying effective election strategies are computationally challenging as minor changes in voter rankings can lead to significant ripple effects - for example, lending support to a losing candidate can prevent their votes from transferring to a more competitive opponent. We study optimal strategies - persuading voters to change their ballots or adding new voters - both algorithmically and theoretically. Algorithmically, we develop efficient methods to reduce election instances while maintaining optimization accuracy, effectively circumventing the computational complexity barrier. Theoretically, we analyze the effectiveness of strategies under both perfect and imperfect polling information. Our algorithmic approach applies to the ranked-choice polling data on the US 2024 Republican Primary, finding, for example, that several candidates would have been optimally served by boosting another candidate instead of themselves.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<strong>Choosing the Right Weights: Balancing Value, Strategy, and Noise in Recommender Systems</strong>





[<a href="javascript:;"onclick=showdropinfo('milliweights23abstract')>abstract</a> | <a href="https://arxiv.org/abs/2305.17428">arxiv</a>]

<script>
  coloryear("milliweights23", 2050, 2024);
</script>

<br><span id="milliweights23">Smitha Milli, Emma Pierson, and Nikhil Garg</span> <br>
 
 


<div id='milliweights23abstract'  class="abstractcollapsed">Many recommender systems are based on optimizing a linear weighting of different user behaviors, such as clicks, likes, shares, etc. Though the choice of weights can have a significant impact, there is little formal study or guidance on how to choose them. We analyze the optimal choice of weights from the perspectives of both users and content producers who strategically respond to the weights. We consider three aspects of user behavior: value-faithfulness (how well a behavior indicates whether the user values the content), strategy-robustness (how hard it is for producers to manipulate the behavior), and noisiness (how much estimation error there is in predicting the behavior). Our theoretical results show that for users, upweighting more value-faithful and less noisy behaviors leads to higher utility, while for producers, upweighting more value-faithful and strategy-robust behaviors leads to higher welfare (and the impact of noise is non-monotonic). Finally, we discuss how our results can help system designers select weights in practice.
  <br></div>



</p>
</li>
<li><p class="reallysmallbib">
<strong>Monoculture in Matching Markets</strong>





[<a href="javascript:;"onclick=showdropinfo('pengmonoculture23abstract')>abstract</a> | <a href="https://arxiv.org/abs/2312.09841">arxiv</a>]

<script>
  coloryear("pengmonoculture23", 2050, 2024);
</script>

<br><span id="pengmonoculture23">Kenny Peng and Nikhil Garg</span> <br>
 
 


<div id='pengmonoculture23abstract'  class="abstractcollapsed">Algorithmic monoculture arises when many decision-makers rely on the same algorithm to evaluate applicants. An emerging body of work investigates possible harms of this kind of homogeneity, but has been limited by the challenge of incorporating market effects in which the preferences and behavior of many applicants and decision-makers jointly interact to determine outcomes.
    
  Addressing this challenge, we introduce a tractable theoretical model of algorithmic monoculture in a two-sided matching market with many participants. We use the model to analyze outcomes under monoculture (when decision-makers all evaluate applicants using a common algorithm) and under polyculture (when decision-makers evaluate applicants independently). All else equal, monoculture (1) selects less-preferred applicants when noise is well-behaved, (2) matches more applicants to their top choice, though individual applicants may be worse off depending on their value to decision-makers and risk tolerance, and (3) is more robust to disparities in the number of applications submitted.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<strong>Algorithms for College Admissions Decision Support: Impacts of Policy Change and Inherent Variability</strong>





[<a href="javascript:;"onclick=showdropinfo('admissionsmlrace24abstract')>abstract</a> | <a href="http://arxiv.org/abs/2407.11199">arxiv</a>]

<script>
  coloryear("admissionsmlrace24", 2050, 2024);
</script>

<br><span id="admissionsmlrace24">Jinsook Lee, Emma Harvey, Joyce Zhou, Nikhil Garg, Thorsten Joachims, and René Kizilcec</span> <br>
 
 


<div id='admissionsmlrace24abstract'  class="abstractcollapsed">Each year, selective American colleges sort through tens of thousands of applications to identify a first-year class that displays both academic merit and diversity. In the 2023-2024 admissions cycle, these colleges faced unprecedented challenges to doing so. First, the number of applications has been steadily growing year-over-year. Second, test-optional policies that have remained in place since the COVID-19 pandemic limit access to key information that has historically been predictive of academic success. Most recently, longstanding debates over affirmative action culminated in the Supreme Court banning race-conscious admissions. Colleges have explored machine learning (ML) models to address the issues of scale and missing test scores, often via ranking algorithms intended to allow human reviewers to focus attention on ‘top’ applicants. However, the Court’s ruling will force changes to these models, which were previously able to consider race as a factor in ranking. There is currently a poor understanding of how these mandated changes will shape applicant ranking algorithms, and, by extension, admitted classes. We seek to address this by quantifying the impact of different admission policies on the applications prioritized for review. We show that removing race data from a previously developed applicant ranking algorithm reduces the diversity of the top-ranked pool of applicants without meaningfully increasing the academic merit of that pool. We contextualize this impact by showing that excluding data on applicant race has a greater impact than excluding other potentially informative variables like intended majors. Finally, we measure the impact of policy change on individuals by comparing the arbitrariness in applicant rank attributable to policy change to the arbitrariness attributable to randomness (i.e., how much an applicant’s rank changes across models that use the same policy but are trained on bootstrapped samples from the same dataset). We find that any given policy has a high degree of arbitrariness (i.e. at most 9% of applicants are consistently ranked in the top 20%), and that removing race data from the ranking algorithm increases arbitrariness in outcomes for most applicants.<br></div>



</p>
</li></ol>
    
  
    
    
    <h2> Journal Articles</h2>
    <ol class="bibliography"><li><p class="reallysmallbib">
<span id="garg_word_2018year">&nbsp;2018&nbsp;</span>&nbsp;<strong>Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes</strong>





[<a href="javascript:;"onclick=showdropinfo('garg_word_2018abstract')>abstract</a> | <a href="https://doi.org/10.1073/pnas.1720347115">official link</a> | <a href="https://github.com/nikhgarg/EmbeddingDynamicStereotypes">code & data</a> | <a href="https://www.youtube.com/watch?v=boxV8Od4jqQ&list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9&index=13">talk</a>]

<script>
  coloryear("garg_word_2018", 2018, 2024);
</script>

<br><span id="garg_word_2018">Nikhil Garg, Londa Schiebinger, Dan Jurafsky, and James Zou</span> <br>
 Proceedings of the National Academy of Sciences (PNAS)<br>
  <i><font color="red">Media</font>: <a href="https://news.stanford.edu/2018/04/03/algorithms-reveal-changes-stereotypes/">Stanford News</a> <a href="https://ee.stanford.edu/news/research-news/04-05-2018/gargnikhil-uses-machine-learning-measure-stereotypes ">(and EE department)</a>, <a href="https://www.sciencemag.org/news/2018/04/artificial-intelligence-reveals-how-us-stereotypes-about-women-and-minorities-have ">Science Magazine</a>, <a href="https://www.smithsonianmag.com ">Smithsonian Magazine</a> <a href="/img/projects/smithsonianpicture.jpg">(in print)</a>, <a href="https://www.weforum.org/agenda/2018/04/algorithms-trace-how-stereotypes-have-changed/">The World Economic Forum</a>, <a href="https://www.futurity.org/algorithm-word-embeddings-stereotypes-bias-1722542/">Futurity</a>, <a href="https://pnas.altmetric.com/details/29305270/news">etc</a>.</i><br> 


<div id='garg_word_2018abstract'  class="abstractcollapsed">Word embeddings are a powerful machine-learning framework that represents each English word by a vector. The geometric relationship between these vectors captures meaningful semantic relationships between the corresponding words. In this paper, we develop a framework to demonstrate how the temporal dynamics of the embedding helps to quantify changes in stereotypes and attitudes toward women and ethnic minorities in the 20th and 21st centuries in the United States. We integrate word embeddings trained on 100 y of text data with the US Census to show that changes in the embedding track closely with demographic and occupation shifts over time. The embedding captures societal shifts - e.g., the women’s movement in the 1960s and Asian immigration into the United States - and also illuminates how specific adjectives and occupations became more closely associated with certain populations over time. Our framework for temporal analysis of word embedding opens up a fruitful intersection between machine learning and quantitative social science.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="garg_iterative_2018year">&nbsp;2019&nbsp;</span>&nbsp;<strong>Iterative Local Voting for Collective Decision-making in Continuous Spaces</strong>





[<a href="javascript:;"onclick=showdropinfo('garg_iterative_2018abstract')>abstract</a> | <a href="javascript:;" onclick=showdropinfo('garg_iterative_2018demo')>demo</a> | <a href="https://www.jair.org/index.php/jair/article/view/11358">official link</a>]

<script>
  coloryear("garg_iterative_2018", 2019, 2024);
</script>

<br><span id="garg_iterative_2018">Nikhil Garg, Vijay Kamble, Ashish Goel, David Marn, and Kamesh Munagala</span> <br>
 Journal of Artificial Intelligence Research (JAIR)<br>
  <i>(Conference version published in WWW‘17.)</i><br> 


<div id='garg_iterative_2018abstract'  class="abstractcollapsed">Many societal decision problems lie in high-dimensional continuous spaces not amenable to the voting techniques common for their discrete or single-dimensional counterparts. These problems are typically discretized before running an election or decided upon through negotiation by representatives. We propose a algorithm called Iterative Local Voting for collective decision-making in this setting. In this algorithm, voters are sequentially sampled and asked to modify a candidate solution within some local neighborhood of its current value, as defined by a ball in some chosen norm, with the size of the ball shrinking at a specified rate.

              We first prove the convergence of this algorithm under appropriate choices of neighborhoods to Pareto optimal solutions with desirable fairness properties in certain natural settings: when the voters’ utilities can be expressed in terms of some form of distance from their ideal solution, and when these utilities are additively decomposable across dimensions. In many of these cases, we obtain convergence to the societal welfare maximizing solution.

              We then describe an experiment in which we test our algorithm for the decision of the U.S. Federal Budget on Mechanical Turk with over 2,000 workers, employing neighborhoods defined by various L-Norm balls. We make several observations that inform future implementations of such a procedure.<br></div>



<div id='garg_iterative_2018demo'  class="abstractcollapsed">  We have a demo of our Mechanical Turk experiment available live <a href="http://54.183.140.235/">here</a>. It can be used as follows:
<ol>
  <li>If the URL is entered without any parameters, it uses the current radius (based on previous uses of the demo, going down by $1/N$) and uses the $\mathcal{L}^2$ mechanism.</li>
  <li>To set the mechanism, navigate to <i>http://54.183.140.235/mechanism/[option]/</i>, where instead of <i>[option]</i> use either, <i>l1</i>, <i>l2</i>, <i>linf</i>, or <i>full</i>, for the respective mechanisms.</li>
  <li>To set the radius, navigate to <i>http://54.183.140.235/mechanism/[number]/</i>, where any integer can be entered instead of <i>[number]</i>. This option resets the starting radius for the specific mechanism, which will go down by $1/N$ in subsequent accesses.</li>
  <li>To set both the mechanism and the radius, navigate to <i>http://54.183.140.235/radius/[number]/mechanism/[option]/</i>, with the above options.</li>
</lo>
</div>

</p>
</li>
<li><p class="reallysmallbib">
<span id="ratings_2020year">&nbsp;2020&nbsp;</span>&nbsp;<strong>Designing Informative Rating Systems: Evidence from an Online Labor Market</strong>





[<a href="javascript:;"onclick=showdropinfo('ratings_2020abstract')>abstract</a> | <a href="https://arxiv.org/abs/1810.13028">arxiv</a> | <a href="https://www.youtube.com/watch?v=dCRVyX_p4K0">talk</a> | <a href="https://pubsonline.informs.org/doi/10.1287/msom.2020.0921">official link</a>]

<script>
  coloryear("ratings_2020", 2020, 2024);
</script>

<br><span id="ratings_2020">Nikhil Garg and Ramesh Johari</span> <br>
 Manufacturing & Service Operations Management<br>
  <i><font color="red">Media</font>: <a href="https://www.nytimes.com/2019/05/25/opinion/sunday/five-star-customer-reviews.html">New York Times</a>, <a href="https://engineering.stanford.edu/magazine/article/story-rated-five-stars">Stanford Engineering magazine</a>.<br>M&SOM student paper award (2nd place), 2020<br>(Conference version published in EC‘20.)</i><br> 


<div id='ratings_2020abstract'  class="abstractcollapsed">Platforms critically rely on rating systems to learn the quality of market participants. In practice, however, these ratings are often highly inflated, drastically reducing the signal available to distinguish quality.  We consider two questions: First, can rating systems better discriminate quality by altering the meaning and relative importance of the levels in the rating system? And second, if so, how should the platform optimize these choices in the design of the rating system?

               We first analyze the results of a randomized controlled trial on an online labor market in which an additional question was added to the feedback form. Between treatment conditions, we vary the question phrasing and answer choices.  We further run an experiment on Amazon Mechanical Turk with similar structure, to confirm the labor market findings. Our tests reveal that current inflationary norms can in fact be countered by re-anchoring the meaning of the levels of the rating system. In particular, scales that are positive-skewed and provide specific interpretations for what each label means yield rating distributions that are much more informative about quality.

               Second, we develop a theoretical framework to optimize the design of a rating system by choosing answer labels and their numeric interpretations in a manner that maximizes the rate of convergence to the true underlying quality distribution. Finally, we run simulations with an empirically calibrated model and use these to study the implications for optimal rating system design. Our simulations demonstrate that our modeling and optimization approach can substantially improve the quality of information obtained over baseline designs.


               Overall, our study illustrates that rating systems that are informative in practice can be designed, and demonstrates how to design them in a principled manner.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="marketspublicgoods_2020year">&nbsp;2020&nbsp;</span>&nbsp;<strong>Markets for Public Decision-making</strong>





[<a href="javascript:;"onclick=showdropinfo('marketspublicgoods_2020abstract')>abstract</a> | <a href="https://arxiv.org/abs/1807.10836">arxiv</a> | <a href="https://rdcu.be/caZFU">official link</a>]

<script>
  coloryear("marketspublicgoods_2020", 2020, 2024);
</script>

<br><span id="marketspublicgoods_2020">Nikhil Garg, Ashish Goel, and Ben Plaut</span> <br>
 Social Choice and Welfare<br>
  <i>(Conference version published in WINE‘18.)</i><br> 


<div id='marketspublicgoods_2020abstract'  class="abstractcollapsed">A public decision-making problem consists of a set of issues, each with multiple possible alternatives, and a set of competing agents, each with a preferred alternative for each issue. We study adaptations of market economies to this setting, focusing on binary issues. Issues have prices, and each agent is endowed with artificial currency that she can use to purchase probability for her preferred alternatives (we allow randomized outcomes). We first show that when each issue has a single price that is common to all agents, market equilibria can be arbitrarily bad. This negative result motivates a different approach. We present a novel technique called "pairwise issue expansion", which transforms any public decision-making instance into an equivalent Fisher market, the simplest type of private goods market. This is done by expanding each issue into many goods: one for each pair of agents who disagree on that issue. We show that the equilibrium prices in the constructed Fisher market yield a "pairwise pricing equilibrium" in the original public decision-making problem which maximizes Nash welfare. More broadly, pairwise issue expansion uncovers a powerful connection between the public decision-making and private goods settings; this immediately yields several interesting results about public decisions markets, and furthers the hope that we will be able to find a simple iterative voting protocol that leads to near-optimum decisions.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="gargdriversurge_19year">&nbsp;2021&nbsp;</span>&nbsp;<strong>Driver Surge Pricing</strong>





[<a href="javascript:;"onclick=showdropinfo('gargdriversurge_19abstract')>abstract</a> | <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3390346">ssrn</a> | <a href="https://github.com/nikhgarg/driver_surge_rideaustin">code & data</a> | <a href="https://www.youtube.com/watch?v=JNsyikrQEHE">talk</a> | <a href="https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2021.4058">official link</a>]

<script>
  coloryear("gargdriversurge_19", 2021, 2024);
</script>

<br><span id="gargdriversurge_19">Nikhil Garg and Hamid Nazerzadeh</span> <br>
 Management Science<br>
  <i>(Conference version published in EC‘20.)</i><br> 


<div id='gargdriversurge_19abstract'  class="abstractcollapsed">Ride-hailing marketplaces like Uber and Lyft use dynamic pricing, often called surge, to balance the supply of available drivers with the demand for rides. We study pricing mechanisms for such marketplaces from the perspective of drivers, presenting the theoretical foundation that has informed the design of Uber’s new additive driver surge mechanism. We present a dynamic stochastic model to capture the impact of surge pricing on driver earnings and their strategies to maximize such earnings. In this setting, some time periods (surge) are more valuable than others (non-surge), and so trips of different time lengths vary in the opportunity cost they impose on drivers. First, we show that multiplicative surge, historically the standard on ride-hailing platforms, is not incentive compatible in a dynamic setting. We then propose a structured, incentive-compatible pricing mechanism. This closed-form mechanism has a simple form and is well-approximated by Uber’s new additive surge mechanism. Finally, through both numerical analysis and real data from a ride-hailing marketplace, we show that additive surge is more approximately incentive compatible in practice than multiplicative surge, providing more stable earnings to drivers.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="liuequitycrowdsourcing22year">&nbsp;2023&nbsp;</span>&nbsp;<strong>Quantifying Spatial Under-reporting Disparities in Resident Crowdsourcing</strong>





[<a href="javascript:;"onclick=showdropinfo('liuequitycrowdsourcing22abstract')>abstract</a> | <a href="https://arxiv.org/abs/2204.08620">arxiv</a> | <a href="https://www.nature.com/articles/s43588-023-00572-6">official link</a> | <a href="https://www.youtube.com/watch?v=Ffhj3aW2gSU&t">talk</a> | <a href="https://github.com/nikhgarg/spatial_underreporting_crowdsourcing">code & data</a>]

<script>
  coloryear("liuequitycrowdsourcing22", 2023, 2024);
</script>

<br><span id="liuequitycrowdsourcing22">Zhi Liu, Uma Bhandaram, and Nikhil Garg</span> <br>
 Nature Computational Science<br>
  <i>Conference version published in ACM Conference on Economics and Computation (EC‘22), titled “Equity in Resident Crowdsourcing: Measuring Under-reporting without Ground Truth Data”<br><font color="red">Media</font>: <a href="https://news.cornell.edu/stories/2023/12/method-may-improve-cities-responses-resident-service-calls">Cornell News</a>.</i><br> 


<div id='liuequitycrowdsourcing22abstract'  class="abstractcollapsed">
    Modern city governance relies heavily on crowdsourcing to identify
    problems such as downed trees and power lines. A major concern is that
    residents do not report problems at the same rates, with heterogeneous
    reporting delays directly translating to downstream disparities in how
    quickly incidents can be addressed. Here we develop a method to identify
    reporting delays without using external ground-truth data. Our insight is
    that the rates at which duplicate reports are made about the same incident
    can be leveraged to disambiguate whether an incident has occurred by
    investigating its reporting rate once it has occurred. We apply our method to
    over 100,000 resident reports made in New York City and to over 900,000
    reports made in Chicago, finding that there are substantial spatial and
    socioeconomic disparities in how quickly incidents are reported. We further
    validate our methods using external data and demonstrate how estimating
    reporting delays leads to practical insights and interventions for a more
    equitable, efficient government service.<br></div>



</p>
</li></ol>
    
  
    
    
    <h2> Peer Reviewed Conference Proceedings (without journal versions)</h2>
    <ol class="bibliography"><li><p class="reallysmallbib">
<span id="garg_impact_2015year">&nbsp;2015&nbsp;</span>&nbsp;<strong>Impact of Dual Slope Path Loss on User Association in HetNets</strong>





[<a href="javascript:;"onclick=showdropinfo('garg_impact_2015abstract')>abstract</a> | <a href="https://doi.org/10.1109/GLOCOMW.2015.7413977">official link</a>]

<script>
  coloryear("garg_impact_2015", 2015, 2024);
</script>

<br><span id="garg_impact_2015">Nikhil Garg, Sarabjot Singh, and Jeffrey Andrews</span> <br>
 IEEE Globecom Workshop<br>
 


<div id='garg_impact_2015abstract'  class="abstractcollapsed">Intelligent load balancing is essential to fully realize the benefits of dense heterogeneous networks. Current techniques have largely been studied with single slope path loss models, though multi-slope models are known to more closely match real deployments. This paper develops insight into the performance of biasing and uplink/downlink decoupling for user association in HetNets with dual slope path loss models. It is shown that dual slope path loss models change the tradeoffs inherent in biasing and reduce gains from both biasing and uplink/downlink decoupling. The results show that with the dual slope path loss models, the bias maximizing the median rate is not optimal for other users, e.g., edge users. Furthermore, optimal downlink biasing is shown to realize most of the gains from downlink-uplink decoupling. Moreover, the user association gains in dense networks are observed to be quite sensitive to the path loss exponent beyond the critical distance in a dual slope model.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="binratingcomparisons_2018year">&nbsp;2019&nbsp;</span>&nbsp;<strong>Designing Optimal Binary Rating Systems</strong>





[<a href="javascript:;"onclick=showdropinfo('binratingcomparisons_2018abstract')>abstract</a> | <a href="http://proceedings.mlr.press/v89/garg19a">official link</a>]

<script>
  coloryear("binratingcomparisons_2018", 2019, 2024);
</script>

<br><span id="binratingcomparisons_2018">Nikhil Garg and Ramesh Johari</span> <br>
 International Conference on Artificial Intelligence and Statistics (AISTATS‘19)<br>
 


<div id='binratingcomparisons_2018abstract'  class="abstractcollapsed">Modern online platforms rely on effective rating systems to learn about items.  We consider the optimal design of rating systems that collect binary feedback after transactions.  We make three contributions.  First, we formalize the performance of a rating system as the speed with which it recovers the true underlying ranking on items (in a large deviations sense), accounting for both items’ underlying match rates and the platform’s preferences.  Second, we provide an efficient algorithm to compute the binary feedback system that yields the highest such performance.  Finally, we show how this theoretical perspective can be used to empirically design an implementable, approximately optimal rating system, and validate our approach using real-world experimental data collected on Amazon Mechanical Turk.
               <br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="demszky_analyzing_2019year">&nbsp;2019&nbsp;</span>&nbsp;<strong>Analyzing Polarization in Social Media: Method and Application to Tweets on 21 Mass Shootings</strong>





[<a href="javascript:;"onclick=showdropinfo('demszky_analyzing_2019abstract')>abstract</a> | <a href="https://arxiv.org/abs/1904.01596">arxiv</a> | <a href="https://github.com/ddemszky/framing-twitter">code & data</a>]

<script>
  coloryear("demszky_analyzing_2019", 2019, 2024);
</script>

<br><span id="demszky_analyzing_2019">Dorottya Demszky, Nikhil Garg, Rob Voigt, James Zou, Jesse Shapiro, Matthew Gentzkow, and Dan Jurafsky</span> <br>
 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL‘19)<br>
  <i><font color="red">Media</font>: <a href="https://www.washingtonpost.com/politics/2019/06/26/democrats-focus-more-victims-republicans-perpetrators-after-mass-shootings-study-finds/?noredirect=on&utm_term=.43380fd237c4">Washington Post</a>, <a href="https://news.stanford.edu/2019/06/25/analyzing-tweets-republicans-democrats/">Stanford News</a>.</i><br> 


<div id='demszky_analyzing_2019abstract'  class="abstractcollapsed">We provide an NLP framework to uncover four linguistic dimensions of political polarization in social media: topic choice, framing, affect and illocutionary force. We quantify these aspects with existing lexical methods, and propose clustering of tweet embeddings as a means to identify salient topics for analysis across events; human evaluations show that our approach generates more cohesive topics than traditional LDA-based models. We apply our methods to study 4.4M tweets on 21 mass shootings. We provide evidence that the discussion of these events is highly polarized politically and that this polarization is primarily driven by partisan differences in framing rather than topic choice. We identify framing devices, such as grounding and the contrasting use of the terms "terrorist" and "crazy", that contribute to polarization. Results pertaining to topic choice, affect and illocutionary force suggest that Republicans focus more on the shooter and event-specific facts (news) while Democrats focus more on the victims and call for policy changes. Our work contributes to a deeper understanding of the way group divisions manifest in language and to computational methods for studying them.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="gargvotermultiwinner_19year">&nbsp;2019&nbsp;</span>&nbsp;<strong>Who is in Your Top Three? Optimizing Learning in Elections with Many Candidates</strong>





[<a href="javascript:;"onclick=showdropinfo('gargvotermultiwinner_19abstract')>abstract</a> | <a href="https://arxiv.org/abs/1906.08160">arxiv</a>]

<script>
  coloryear("gargvotermultiwinner_19", 2019, 2024);
</script>

<br><span id="gargvotermultiwinner_19">Nikhil Garg, Lodewijk Gelauff, Sukolsak Sakshuwong, and Ashish Goel</span> <br>
 AAAI Conference on Human Computation and Crowdsourcing (HCOMP‘19)<br>
 


<div id='gargvotermultiwinner_19abstract'  class="abstractcollapsed">Elections and opinion polls often have many candidates, with the aim to either rank the candidates or identify a small set of winners according to voters’ preferences. In practice, voters do not provide a full ranking; instead, each voter provides their favorite K candidates, potentially in ranked order. The election organizer must choose K and an aggregation rule.

               We provide a theoretical framework to make these choices. Each K-Approval or K-partial ranking mechanism (with a corresponding positional scoring rule) induces a learning rate for the speed at which the election correctly recovers the asymptotic outcome. Given the voter choice distribution, the election planner can thus identify the rate optimal mechanism. Earlier work in this area provides coarse order-of-magnitude guaranties which are not sufficient to make such choices.
               Our framework further resolves questions of when randomizing between multiple mechanisms may improve learning, for arbitrary voter noise models.

               Finally, we use data from 5 large participatory budgeting elections that we organized across several US cities, along with other ranking data, to demonstrate the utility of our methods. In particular, we find that historically such elections have set K too low and that picking the right mechanism can be the difference between identifying the correct winner with only a 80% probability or a 99.9% probability after 500 voters.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="caifairallocation_19year">&nbsp;2020&nbsp;</span>&nbsp;<strong>Fair Allocation through Selective Information Acquisition</strong>





[<a href="javascript:;"onclick=showdropinfo('caifairallocation_19abstract')>abstract</a> | <a href="https://arxiv.org/abs/1911.02715">arxiv</a>]

<script>
  coloryear("caifairallocation_19", 2020, 2024);
</script>

<br><span id="caifairallocation_19">William Cai, Johann Gaebler, Nikhil Garg, and Sharad Goel</span> <br>
 AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES‘20)<br>
 


<div id='caifairallocation_19abstract'  class="abstractcollapsed">Public and private institutions must often
               allocate scare resources under uncertainty.
               Banks, for example, extend credit to loan applicants based in part on their estimated likelihood of repaying a loan.
               But when the quality of information differs across candidates (e.g., if some applicants lack traditional credit histories), common lending strategies can lead to disparities across groups. Here we consider a setting in which decision makers—before allocating resources—can choose to spend some of their limited budget further screening select individuals. We present a computationally efficient algorithm for deciding whom to screen that maximizes a standard measure of social welfare.
               Intuitively, decision makers should screen candidates on the margin, for whom the additional information could plausibly alter the allocation. We formalize this idea by showing the problem can be reduced to solving a series of linear programs. Both on synthetic and real-world datasets, this strategy improves utility, illustrating the value of targeted information acquisition in such decisions. Further, when there is social value for distributing resources to groups for whom we have a priori poor information—like those without credit scores—our approach can substantially improve the allocation of limited assets.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="gargbiastest_20year">&nbsp;2021&nbsp;</span>&nbsp;<strong>Dropping Standardized Testing for Admissions: Differential Variance and Access</strong>





[<a href="javascript:;"onclick=showdropinfo('gargbiastest_20abstract')>abstract</a> | <a href="https://arxiv.org/abs/2010.04396">arxiv</a>]

<script>
  coloryear("gargbiastest_20", 2021, 2024);
</script>

<br><span id="gargbiastest_20">Nikhil Garg, Hannah Li, and Faidra Monachou</span> <br>
 ACM Conference on Fairness, Accountability, and Transparency (FAccT‘21)<br>
  <i>Also appeared in EAAMO‘21, with Best Student Paper Award<br>Appeared in the 2021 NBER Decentralization Conference</i><br> 


<div id='gargbiastest_20abstract'  class="abstractcollapsed">
                 The University of California suspended through 2024 the requirement that applicants from California submit SAT scores, upending the major role standardized testing has played in college admissions. We study the impact of such decisions and its interplay with other intervention such as affirmative action on admitted class composition.
                 More specifically, this paper develops a theoretical framework to study the effect of requiring test scores on academic merit and diversity in college admissions. The model has a college and set of potential students. Each student an unobserved noisy skill level, and multiple observed application components and group membership. The college is Bayesian and maximizes an objective that depends on both diversity and merit. It estimates each applicant’s true skill level using the observed features, and then admits students with or without affirmative action.
                 We characterize the trade-off between the (potentially positive) informational role of standardized testing in college admissions and its (negative) exclusionary nature. Dropping test scores may exacerbate disparities by decreasing the amount of information available for each applicant, especially those from non-traditional backgrounds. However, if there are substantial barriers to testing, removing the test improves both academic merit and diversity by increasing the size of the applicant pool. The overall effect of testing depends on both the variance of the test score noise and the amount of people excluded by the test requirement.
                 Finally, using application and transcript data from the University of Texas at Austin, we demonstrate how an admissions committee could measure the trade-off in practice.
                 <br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="liusoptionaltests21year">&nbsp;2021&nbsp;</span>&nbsp;<strong>Test-optional Policies: Overcoming Strategic Behavior and Informational Gaps</strong>





[<a href="javascript:;"onclick=showdropinfo('liusoptionaltests21abstract')>abstract</a> | <a href="https://arxiv.org/abs/2107.08922">arxiv</a>]

<script>
  coloryear("liusoptionaltests21", 2021, 2024);
</script>

<br><span id="liusoptionaltests21">Zhi Liu and Nikhil Garg</span> <br>
 AAAI/ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization (EAAMO‘21)<br>
 


<div id='liusoptionaltests21abstract'  class="abstractcollapsed">
               Due to the Covid-19 pandemic, more than 500 US-based colleges and universities went “test-optional” for admissions and promised that they would not penalize applicants for not submitting test scores, part of a longer trend to rethink the role of testing in college admissions. However, it remains unclear how (and whether) a college can simultaneously use test scores for those who submit them, while not penalizing those who do not–and what that promise even means. We formalize these questions, and study how a college can overcome two challenges with optional testing: strategic applicants  (when those with low test scores can pretend to not have taken the test), and informational gaps (it has more information on those who submit a test score than those who do not). We find that colleges can indeed do so, if and only if they are able to use information on who has test access and are willing to randomize admissions.
               <br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="guovector21year">&nbsp;2021&nbsp;</span>&nbsp;<strong>The Stereotyping Problem in Collaboratively Filtered Recommender Systems</strong>





[<a href="javascript:;"onclick=showdropinfo('guovector21abstract')>abstract</a> | <a href="https://arxiv.org/abs/2106.12622">arxiv</a>]

<script>
  coloryear("guovector21", 2021, 2024);
</script>

<br><span id="guovector21">Wenshuo Guo, Karl Krauth, Michael I. Jordan, and Nikhil Garg</span> <br>
 AAAI/ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization (EAAMO‘21)<br>
 


<div id='guovector21abstract'  class="abstractcollapsed">
               Recommender systems – and especially matrix factorization-based collaborative filtering algorithms – play a crucial role in mediating our access to online information. We show that such algorithms induce a particular kind of stereotyping: if preferences for a set of items are anti-correlated in the general user population, then those items may not be recommended together to a user, regardless of that user’s preferences and ratings history. First, we introduce a notion of joint accessibility, which measures the extent to which a set of items can jointly be accessed by users. We then study joint accessibility under the standard factorization-based collaborative filtering framework, and provide theoretical necessary and sufficient conditions when joint accessibility is violated. Moreover, we show that these conditions can easily be violated when the users are represented by a single feature vector.
               To improve joint accessibility,  we further propose an alternative modelling fix, which is designed to capture the diverse multiple interests of each user using a multi-vector representation. We conduct extensive experiments on real and simulated datasets, demonstrating the stereotyping problem with standard single-vector matrix factorization models.
               <br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="liusrategicranking21year">&nbsp;2022&nbsp;</span>&nbsp;<strong>Strategic Ranking</strong>





[<a href="javascript:;"onclick=showdropinfo('liusrategicranking21abstract')>abstract</a> | <a href="https://arxiv.org/abs/2109.08240">arxiv</a>]

<script>
  coloryear("liusrategicranking21", 2022, 2024);
</script>

<br><span id="liusrategicranking21">Lydia Liu, Nikhil Garg, and Christian Borgs</span> <br>
 International Conference on Artificial Intelligence and Statistics (AISTATS‘22)<br>
 


<div id='liusrategicranking21abstract'  class="abstractcollapsed">
                 Strategic classification studies the design of a classifier robust to the manipulation of input by strategic individuals. However, the existing literature does not consider the effect of competition among individuals as induced by the algorithm design. Motivated by constrained allocation settings such as college admissions, we introduce strategic ranking, in which the (designed) individual reward depends on an applicant’s post-effort rank in a measurement of interest. Our results illustrate how competition among applicants affects the resulting equilibria and model insights. We analyze how various ranking reward designs trade off applicant, school, and societal utility and in particular how ranking design can counter inequities arising from disparate access to resources to improve one’s measured score: We find that randomization in the ranking reward design can mitigate two measures of disparate impact, welfare gap and access, whereas non-randomization may induce a high level of competition that systematically excludes a disadvantaged group.
                 <br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="patro2022fairyear">&nbsp;2022&nbsp;</span>&nbsp;<strong>Fair ranking: a critical review, challenges, and future directions</strong>





[<a href="javascript:;"onclick=showdropinfo('patro2022fairabstract')>abstract</a> | <a href="https://arxiv.org/abs/2201.12662">arxiv</a> | <a href="https://doi.org/10.1145/3531146.3533238">official link</a>]

<script>
  coloryear("patro2022fair", 2022, 2024);
</script>

<br><span id="patro2022fair">Gourab K Patro, Lorenzo Porcaro, Laura Mitchell, Qiuyue Zhang, Meike Zehlike, and Nikhil Garg</span> <br>
 ACM Conference on Fairness, Accountability, and Transparency (FAccT‘22)<br>
  <i>This work was written as part of a distributed, student-led working group of <a href="https://www.md4sg.com/">Mechanism Design for Social Good</a></i><br> 


<div id='patro2022fairabstract'  class="abstractcollapsed">
    Ranking, recommendation, and retrieval systems are widely used in online platforms and other societal systems, including e-commerce, media-streaming, admissions, gig platforms, and hiring. In the recent past, a large "fair ranking" research literature has been developed around making these systems fair to the individuals, providers, or content that are being ranked. Most of this literature defines fairness for a single instance of retrieval, or as a simple additive notion for multiple instances of retrievals over time. This work provides a critical overview of this literature, detailing the often context-specific concerns that such an approach misses: the gap between high ranking placements and true provider utility, spillovers and compounding effects over time, induced strategic incentives, and the effect of statistical uncertainty. We then provide a path forward for a more holistic and impact-oriented fair ranking research agenda, including methodological lessons from other fields and the role of the broader stakeholder community in overcoming data bottlenecks and designing effective regulatory environments.
    <br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="ZPTrucks22year">&nbsp;2022&nbsp;</span>&nbsp;<strong>Trucks Don’t Mean Trump: Diagnosing Human Error in Image Analysis</strong>





[<a href="javascript:;"onclick=showdropinfo('ZPTrucks22abstract')>abstract</a> | <a href="https://arxiv.org/abs/2205.07333">arxiv</a> | <a href="doi.acm.org?doi=3531146.3533145">official link</a>]

<script>
  coloryear("ZPTrucks22", 2022, 2024);
</script>

<br><span id="ZPTrucks22">J.D. Zamfirescu-Pereira, Jerry Chen, Emily Wen, Allison Koenecke, Nikhil Garg, and Emma Pierson</span> <br>
 ACM Conference on Fairness, Accountability, and Transparency (FAccT‘22)<br>
  <i><font color="red">Media</font>: <a href="https://cis.cornell.edu/do-trucks-mean-trump-ai-shows-how-humans-misjudge-images">Cornell News</a>.</i><br> 


<div id='ZPTrucks22abstract'  class="abstractcollapsed">Algorithms provide powerful tools for detecting and dissecting human bias and error. Here, we develop machine learning methods to to analyze how humans err in a particular high-stakes task: image interpretation. We leverage a unique dataset of 16,135,392 human predictions of whether a neighborhood voted for Donald Trump or Joe Biden in the 2020 US election, based on a Google Street View image. We show that by training a machine learning estimator of the Bayes optimal decision for each image, we can provide an actionable decomposition of human error into bias, variance, and noise terms, and further identify specific features (like pickup trucks) which lead humans astray. Our methods can be applied to ensure that human-in-the-loop decision-making is accurate and fair and are also applicable to black-box algorithmic systems.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="garggerrysocialchoice21year">&nbsp;2022&nbsp;</span>&nbsp;<strong>Combatting Gerrymandering with Social Choice: the Design of Multi-member Districts</strong>





[<a href="javascript:;"onclick=showdropinfo('garggerrysocialchoice21abstract')>abstract</a> | <a href="https://arxiv.org/abs/2107.07083">arxiv</a>]

<script>
  coloryear("garggerrysocialchoice21", 2022, 2024);
</script>

<br><span id="garggerrysocialchoice21">Nikhil Garg, Wes Gurnee, David Rothschild, and David Shmoys</span> <br>
 ACM Conference on Economics and Computation (EC‘22)<br>
  <i><font color="red">Media</font>: <a href="https://news.cornell.edu/stories/2021/09/ranked-choice-multimember-districts-blunts-gerrymandering">Cornell Chronicle</a>.</i><br> 


<div id='garggerrysocialchoice21abstract'  class="abstractcollapsed">
                 Every representative democracy must specify a mechanism under which voters choose their representatives. The most common mechanism in the United States – winner-take-all single-member districts – both enables substantial partisan gerrymandering and constrains‘fair’ redistricting, preventing proportional representation in legislatures. We study the design of multi-member districts (MMDs), in which each district elects multiple representatives, potentially through a non-winner-takes-all voting rule. We carry out large-scale analyses for the U.S. House of Representatives under MMDs with different social choice functions, under algorithmically generated maps optimized for either partisan benefit or proportionality. Doing so requires efficiently incorporating predicted partisan outcomes – under various multi-winner social choice functions – into an algorithm that optimizes over an ensemble of maps. We find that with three-member districts using Single Transferable Vote, fairness-minded independent commissions would be able to achieve proportional outcomes in every state up to rounding, and advantage-seeking partisans would have their power to gerrymander significantly curtailed. Simultaneously, such districts would preserve geographic cohesion, an arguably important aspect of representative democracies. In the process, we open up a rich research agenda at the intersection of social choice and computational redistricting.  <br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="racedisparities23year">&nbsp;2023&nbsp;</span>&nbsp;<strong>Coarse race data conceals disparities in clinical risk score performance
  </strong>





[<a href="javascript:;"onclick=showdropinfo('racedisparities23abstract')>abstract</a> | <a href="https://arxiv.org/abs/2304.09270">arxiv</a>]

<script>
  coloryear("racedisparities23", 2023, 2024);
</script>

<br><span id="racedisparities23">Rajiv Movva, Divya Shanmugam, Kaihua Hou, Priya Pathak, John Guttag, Nikhil Garg, and Emma Pierson</span> <br>
 Machine Learning for Healthcare (ML4HC)<br>
 


<div id='racedisparities23abstract'  class="abstractcollapsed">Healthcare data in the United States often records only a patient’s coarse race group: for example, both Indian and Chinese patients are typically coded as “Asian.” It is unknown, however, whether this coarse coding conceals meaningful disparities in the performance of clinical risk scores across granular race groups. Here we show that it does. Using data from 418K emergency department visits, we assess clinical risk score performance disparities across granular race groups for three outcomes, five risk scores, and four performance metrics. Across outcomes and metrics, we show that there are significant granular disparities in performance within coarse race categories. In fact, variation in performance metrics within coarse groups often exceeds the variation between coarse groups. We explore why these disparities arise, finding that outcome rates, feature distributions, and the relationships between features and outcomes all vary significantly across granular race categories. Our results suggest that healthcare providers, hospital systems, and machine learning researchers should strive to collect, release, and use granular race data in place of coarse race data, and that existing analyses may significantly underestimate racial disparities in performance.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="recsyspiki23year">&nbsp;2023&nbsp;</span>&nbsp;<strong>Interface Design to Mitigate Inflation in Recommender Systems
  </strong>





[<a href="javascript:;"onclick=showdropinfo('recsyspiki23abstract')>abstract</a> | <a href="https://doi.org/10.1145/3604915.3608846">official link</a>]

<script>
  coloryear("recsyspiki23", 2023, 2024);
</script>

<br><span id="recsyspiki23">Rana Shahout, Yehonatan Peisakhovsky, Sasha Stoikov, and Nikhil Garg</span> <br>
 ACM Conference on Recommender Systems (RecSys ’23 Short paper)<br>
 


<div id='recsyspiki23abstract'  class="abstractcollapsed">Recommendation systems rely on user-provided data to learn about item quality and provide personalized recommendations. An implicit assumption when aggregating ratings into item quality is that ratings are strong indicators of item quality. In this work, we test this assumption using data collected from a music discovery application. Our study focuses on two factors that cause rating inflation: heterogeneous user rating behavior and the dynamics of personalized recommendations.
  We show that user rating behavior is substantially varies by user, leading to item quality estimates that reflect the users who rated an item more than the item quality itself. Additionally, items that are more likely to be shown via personalized recommendations can experience a substantial increase in their exposure and potential bias toward them. To mitigate these effects, we analyze the results of a randomized controlled trial in which the rating interface was modified. The test resulted in a substantial improvement in user rating behavior and a reduction in item quality inflation. These findings highlight the importance of carefully considering the assumptions underlying recommendation systems and designing interfaces that encourage accurate rating behavior.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="vincefield23year">&nbsp;2023&nbsp;</span>&nbsp;<strong>Faster Information for Effective LTC Discharge, A Field Study in Adult Foster Care</strong>





[<a href="javascript:;"onclick=showdropinfo('vincefield23abstract')>abstract</a>]

<script>
  coloryear("vincefield23", 2023, 2024);
</script>

<br><span id="vincefield23">Vince Bartle, Nicola Dell, and Nikhil Garg</span> <br>
 ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization (EAAMO‘23)<br>
 


<div id='vincefield23abstract'  class="abstractcollapsed">A growing proportion of the population is elderly. With this aging population, an increasing challenge is placing patients into adult foster care facilities, which are small long-term care nursing facilities. A key challenge is the dynamic matching process between hospital discharge coordinators looking to place patients, and facilities looking for residents. This paper describes the design and implementation of a 12 month deployment to support decision making among a team of 6 social workers assisting in the discharge of 107 long term care patients across 1,047 potential care facilities. Our system collected vacancy and capability data from facilities over time through conversational SMS. We then process the data to provide call recommendations as to which homes might be best for social workers to contact. We show that our system had sustained engagement over the duration of the deployment and provide evidence of the impact that timely, accurate information has on easing long-term care patient matching. Overall, we demonstrate that platforms for information exchange – even absent algorithmic recommendation or matching – can increase matching efficacy. We further provide lessons for designing information collection systems and provisioning platforms in similar contexts.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="jagadeesan23year">&nbsp;2023&nbsp;</span>&nbsp;<strong>Supply-Side Equilibria in Recommender Systems</strong>





[<a href="javascript:;"onclick=showdropinfo('jagadeesan23abstract')>abstract</a> | <a href="https://arxiv.org/abs/2206.13489">arxiv</a>]

<script>
  coloryear("jagadeesan23", 2023, 2024);
</script>

<br><span id="jagadeesan23">Meena Jagadeesan, Nikhil Garg, and Jacob Steinhardt</span> <br>
 Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS ‘23)<br>
 


<div id='jagadeesan23abstract'  class="abstractcollapsed">Digital recommender systems such as Spotify and Netflix affect not only consumer behavior but also producer incentives: producers seek to supply content that will be recommended by the system. But what content will be produced? In this paper, we investigate the supply-side equilibria in content recommender systems. We model users and content as D-dimensional vectors, and recommend the content that has the highest dot product with each user. The main features of our model are that the producer decision space is high-dimensional and the user base is heterogeneous. This gives rise to new qualitative phenomena at equilibrium: First, the formation of genres, where producers specialize to compete for subsets of users. Using a duality argument, we derive necessary and sufficient conditions for this specialization to occur. Second, we show that producers can achieve positive profit at equilibrium, which is typically impossible under perfect competition. We derive sufficient conditions for this to occur, and show it is closely connected to specialization of content. In both results, the interplay between the geometry of the users and the structure of producer costs influences the structure of the supply-side equilibria. At a conceptual level, our work serves as a starting point to investigate how recommender systems shape supply-side competition between producers.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="networksunder23year">&nbsp;2024&nbsp;</span>&nbsp;<strong>A Bayesian Spatial Model to Correct Under-Reporting in Urban Crowdsourcing</strong>





[<a href="javascript:;"onclick=showdropinfo('networksunder23abstract')>abstract</a> | <a href="https://doi.org/10.1609/aaai.v38i20.30190">official link</a> | <a href="https://arxiv.org/abs/2312.11754">arxiv</a> | <a href="https://github.com/gsagostini/networks_underreporting/">code & data</a>]

<script>
  coloryear("networksunder23", 2024, 2024);
</script>

<br><span id="networksunder23">Gabriel Agostini, Emma Pierson, and Nikhil Garg</span> <br>
 AAAI Conference on Artificial Intelligence (AAAI‘24) (Oral Presentation)<br>
 


<div id='networksunder23abstract'  class="abstractcollapsed">Decision-makers often observe the occurrence of events through a reporting process. City governments, for example, rely on resident reports to find and then resolve urban infrastructural problems such as fallen street trees, flooded basements, or rat infestations. Without additional assumptions, there is no way to distinguish events that occur but are not reported from events that truly did not occur–a fundamental problem in settings with positive-unlabeled data. Because disparities in reporting rates correlate with resident demographics, addressing incidents only on the basis of reports leads to systematic neglect in neighborhoods that are less likely to report events. We show how to overcome this challenge by leveraging the fact that events are \textitspatially correlated. Our framework uses a Bayesian spatial latent variable model to infer event occurrence probabilities and applies it to storm-induced flooding reports in New York City, further pooling results across multiple storms. We show that a model accounting for under-reporting and spatial correlation predicts future reports more accurately than other models, and further induces a more equitable set of inspections: its allocations better reflect the population and provide equitable service to non-white and lower-income areas. This finding reflects heterogeneous reporting behavior learned by the model: reporting rates are higher in Census tracts with higher populations, proportions of white residents, and proportions of owner-occupied households. Our work lays the groundwork for more equitable proactive government services, even with disparate reporting behavior.  <br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="library24year">&nbsp;2024&nbsp;</span>&nbsp;<strong>Identifying and Addressing Disparities in Public Libraries with Bayesian Latent Variable Modeling</strong>





[<a href="javascript:;"onclick=showdropinfo('library24abstract')>abstract</a> | <a href="https://doi.org/10.1609/aaai.v38i20.30231">official link</a> | <a href="https://github.com/ZhiLiu724/library_disparities">code & data</a>]

<script>
  coloryear("library24", 2024, 2024);
</script>

<br><span id="library24">Zhi Liu, Sarah Rankin, and Nikhil Garg</span> <br>
 AAAI Conference on Artificial Intelligence (AAAI‘24)<br>
 


<div id='library24abstract'  class="abstractcollapsed">Public libraries are an essential public good. We ask: are urban library systems providing equitable service to all residents, in terms of the books they have access to and check out? If not, what causes disparities: heterogeneous book collections, resident behavior and access, and/or operational policies? Existing methods leverage only system-level outcome data (such as overall checkouts per branch), and so cannot distinguish between these factors. As a result, it is difficult to use their results to guide interventions to increase equitable access. We propose a Bayesian framework to characterize book checkout behavior across multiple branches of a library system, learning heterogeneous book popularity, overall branch demand, and usage of the online hold system, while controlling for book availability.

In collaboration with the New York Public Library, we apply our framework to granular data consisting of over 400,000 checkouts during 2022. We first show that our model significantly out-performs baseline methods in predicting checkouts at the book-branch level. Next, we study spatial and socioeconomic disparities. We show that disparities are largely driven by disparate use of the online holds system, which allows library patrons to receive books from any other branch through an online portal. This system thus leads to a large outflow of popular books from branches in lower income neighborhoods to those in high income ones. Finally, we illustrate the use of our model and insights to quantify the impact of potential interventions, such as changing how books are internally routed between branches to fulfill hold requests.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="missingdomainyear">&nbsp;2024&nbsp;</span>&nbsp;<strong>Domain constraints improve risk prediction when outcome data is missing</strong>





[<a href="javascript:;"onclick=showdropinfo('missingdomainabstract')>abstract</a> | <a href="https://arxiv.org/abs/2312.03878">arxiv</a>]

<script>
  coloryear("missingdomain", 2024, 2024);
</script>

<br><span id="missingdomain">Sidhika Balachandar, Nikhil Garg, and Emma Pierson</span> <br>
 International Conference on Learning Representations (ICLR‘24)<br>
 


<div id='missingdomainabstract'  class="abstractcollapsed">Machine learning models are often trained to predict the outcome resulting from a human decision. For example, if a doctor decides to test a patient for disease, will the patient test positive? A challenge is that the human decision censors the outcome data: we only observe test outcomes for patients doctors historically tested. Untested patients, for whom outcomes are unobserved, may differ from tested patients along observed and unobserved dimensions. We propose a Bayesian model class which captures this setting. The purpose of the model is to accurately estimate risk for both tested and untested patients. Estimating this model is challenging due to the wide range of possibilities for untested patients. To address this, we propose two domain constraints which are plausible in health settings: a prevalence constraint, where the overall disease prevalence is known, and an expertise constraint, where the human decision-maker deviates from purely risk-based decision-making only along a constrained feature set. We show theoretically and on synthetic data that domain constraints improve parameter inference. We apply our model to a case study of cancer risk prediction, showing that the model’s inferred risk predicts cancer diagnoses, its inferred testing policy captures known public health policies, and it can identify suboptimalities in test allocation. Though our case study is in healthcare, our analysis reveals a general class of domain constraints which can improve model estimation in many settings.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="pengdiverseaccuracy23year">&nbsp;2024&nbsp;</span>&nbsp;<strong>Reconciling the accuracy-diversity trade-off in recommendations</strong>





[<a href="javascript:;"onclick=showdropinfo('pengdiverseaccuracy23abstract')>abstract</a> | <a href="https://arxiv.org/abs/2307.15142.pdf">arxiv</a> | <a href="https://dl.acm.org/doi/10.1145/3589334.3645625">official link</a>]

<script>
  coloryear("pengdiverseaccuracy23", 2024, 2024);
</script>

<br><span id="pengdiverseaccuracy23">Kenny Peng, Manish Raghavan, Emma Pierson, Jon Kleinberg, and Nikhil Garg</span> <br>
 The ACM Web Conference (WWW‘24) (Oral Presentation)<br>
 


<div id='pengdiverseaccuracy23abstract'  class="abstractcollapsed">In recommendation settings, there is an apparent trade-off between the goals of accuracy (to recommmend items a user is most likely to want) and diversity (to recommend items representing a range of categories). As such, real-world recommender systems often explicitly incorporate diversity separately from accuracy. This approach, however, leaves a basic question unanswered: Why is there a trade-off in the first place? We analyze a stylized model of recommendations reconciling this trade-off. Accounting for a user’s capacity constraints (users do not typically make use of all the items that are recommended to them), optimal recommendations in our model are inherently diverse. Thus, accuracy and diversity appear misaligned because traditional accuracy metrics do not consider capacity constraints. Our model yields precise and interpretable characterizations of diversity in different settings, giving practical insights into the design of diverse recommendations.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="argmaxdisparities24year">&nbsp;2024&nbsp;</span>&nbsp;<strong>Addressing Discretization-Induced Bias in Demographic Prediction</strong>





[<a href="javascript:;"onclick=showdropinfo('argmaxdisparities24abstract')>abstract</a> | <a href="https://arxiv.org/abs/2405.16762">arxiv</a>]

<script>
  coloryear("argmaxdisparities24", 2024, 2024);
</script>

<br><span id="argmaxdisparities24">Evan Dong, Aaron Schein, Yixin Wang, and Nikhil Garg</span> <br>
 ACM Conference on Fairness, Accountability, and Transparency (FAccT‘24)<br>
 


<div id='argmaxdisparities24abstract'  class="abstractcollapsed">Racial and other demographic imputation is necessary for many applications, especially in auditing disparities and outreach targeting in political campaigns. The canonical approach is to construct continuous predictions – e.g., based on name and geography – and then to discretize the predictions by selecting the most likely class (argmax). We study how this practice produces discretization bias. In particular, we show that argmax labeling, as used by a prominent commercial voter file vendor to impute race/ethnicity, results in a substantial under-count of African-American voters, e.g., by 28.2% points in North Carolina. This bias can have substantial implications in downstream tasks that use such labels.
  We then introduce a joint optimization approach – and a tractable data-driven thresholding heuristic – that can eliminate this bias, with negligible individual-level accuracy loss. Finally, we theoretically analyze discretization bias, show that calibrated continuous models are insufficient to eliminate it, and that an approach such as ours is necessary. Broadly, we warn researchers and practitioners against discretizing continuous demographic predictions without considering downstream consequences.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="llmhackathaon23year">&nbsp;2024&nbsp;</span>&nbsp;<strong>Large language models shape and are shaped by society: A survey of arXiv publication patterns</strong>





[<a href="javascript:;"onclick=showdropinfo('llmhackathaon23abstract')>abstract</a> | <a href="https://arxiv.org/abs/2307.10700">arxiv</a>]

<script>
  coloryear("llmhackathaon23", 2024, 2024);
</script>

<br><span id="llmhackathaon23">Rajiv Movva, Sidhika Balachandar, Kenny Peng, Gabriel Agostini, Nikhil Garg, and Emma Pierson</span> <br>
 The North American Chapter of the Association for Computational Linguistics (NAACL‘24)<br>
 


<div id='llmhackathaon23abstract'  class="abstractcollapsed">There has been a steep recent increase in the number of large language model (LLM) papers, producing a dramatic shift in the scientific landscape which remains largely undocumented through bibliometric analysis. Here, we analyze 388K papers posted on the CS and Stat arXivs, focusing on changes in publication patterns in 2023 vs. 2018-2022. We analyze how the proportion of LLM papers is increasing; the LLM-related topics receiving the most attention; the authors writing LLM papers; how authors’ research topics correlate with their backgrounds; the factors distinguishing highly cited LLM papers; and the patterns of international collaboration. We show that LLM research increasingly focuses on societal impacts: there has been an 18x increase in the proportion of LLM-related papers on the Computers and Society sub-arXiv, and authors newly publishing on LLMs are more likely to focus on applications and societal impacts than more experienced authors. LLM research is also shaped by social dynamics: we document gender and academic/industry disparities in the topics LLM authors focus on, and a US/China schism in the collaboration network. Overall, our analysis documents the profound ways in which LLM research both shapes and is shaped by society, attesting to the necessity of sociotechnical lenses.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="pengwisdomnoisy24year">&nbsp;2024&nbsp;</span>&nbsp;<strong>Wisdom and Foolishness of Noisy Matching Markets  </strong>





[<a href="javascript:;"onclick=showdropinfo('pengwisdomnoisy24abstract')>abstract</a> | <a href="https://arxiv.org/abs/2402.16771">arxiv</a>]

<script>
  coloryear("pengwisdomnoisy24", 2024, 2024);
</script>

<br><span id="pengwisdomnoisy24">Kenny Peng and Nikhil Garg</span> <br>
 ACM Conference on Economics and Computation (EC‘24)<br>
 


<div id='pengwisdomnoisy24abstract'  class="abstractcollapsed">We consider a many-to-one matching market where colleges share true preferences over students but make decisions using only independent noisy rankings. Each student has a \textittrue value v, but each college c ranks the student according to an independently drawn \textitestimated value v + X_c for X_c∼\DD. We ask a basic question about the resulting stable matching: How noisy is the set of matched students? Two striking effects can occur in large markets (i.e., with a continuum of students and a large number of colleges). When \DD is light-tailed, noise is fully attenuated: only the highest-value students are matched. When \DD is long-tailed, noise is fully amplified: students are matched uniformly at random. These results hold for any distribution of student preferences over colleges, and extend to when only subsets of colleges agree on true student valuations instead of the entire market. More broadly, our framework provides a tractable approach to analyze implications of imperfect preference formation in large markets.
  <br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="LiuSLA24year">&nbsp;2024&nbsp;</span>&nbsp;<strong>Redesigning Service Level Agreements: Equity and Efficiency in City Government Operations</strong>







<script>
  coloryear("LiuSLA24", 2024, 2024);
</script>

<br><span id="LiuSLA24">Zhi Liu and Nikhil Garg</span> <br>
 ACM Conference on Economics and Computation (EC‘24)<br>
 




</p>
</li>
<li><p class="reallysmallbib">
<span id="Congestion24year">&nbsp;2024&nbsp;</span>&nbsp;<strong>Equitable Congestion Pricing under the Markovian Traffic Model: An Application to Bogota</strong>





[<a href="javascript:;"onclick=showdropinfo('Congestion24abstract')>abstract</a> | <a href="https://arxiv.org/abs/2407.05035">arxiv</a>]

<script>
  coloryear("Congestion24", 2024, 2024);
</script>

<br><span id="Congestion24">Alfredo Torrico, Natthawut Boonsiriphatthanajaroen, Nikhil Garg, Andrea Lodi, and Hugo Mainguy</span> <br>
 ACM Conference on Economics and Computation (EC‘24)<br>
 


<div id='Congestion24abstract'  class="abstractcollapsed">Congestion pricing is used to raise revenues and reduce traffic and pollution. However, people have heterogeneous spatial demand patterns and willingness (or ability) to pay tolls, and so pricing may have substantial equity implications. We develop a data-driven approach to design congestion pricing given policymakers’ equity and efficiency objectives. First, algorithmically, we extend the Markovian traffic equilibrium setting introduced by Baillon & Cominetti (2008) to model heterogeneous populations and incorporate prices and outside options such as public transit. Second, we empirically evaluate various pricing schemes using data collected by an industry partner in the city of Bogota, one of the most congested cities in the world. We find that pricing personalized to each economic stratum can be substantially more efficient and equitable than uniform pricing; however, non-personalized but area-based pricing can recover much of the gap.
<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="producerfairness23year">&nbsp;2025&nbsp;</span>&nbsp;<strong>Balancing Producer Fairness and Efficiency via Bayesian Rating System Design</strong>





[<a href="javascript:;"onclick=showdropinfo('producerfairness23abstract')>abstract</a> | <a href="https://arxiv.org/abs/2207.04369">arxiv</a>]

<script>
  coloryear("producerfairness23", 2025, 2024);
</script>

<br><span id="producerfairness23">Thomas Ma, Michael Bernstein, Ramesh Johari, and Nikhil Garg</span> <br>
 International AAAI Conference on Web and Social Media (ICWSM ‘25)<br>
 


<div id='producerfairness23abstract'  class="abstractcollapsed">Online marketplaces use rating systems to promote discovery of high quality products. However, these systems also lead to high variance in producers’ economic outcomes: a new producer who sells high-quality items, may, by luck, receive one low rating early on, negatively impacting their popularity with future customers. We investigate the design of rating systems that balance the goals of identifying high quality products ("efficiency") and minimizing the variance in economic outcomes of producers of similar quality (individual "producer fairness"). We observe that there is a trade-off between these two goals: rating systems that promote efficiency are necessarily less individually fair to producers. We introduce Bayesian rating systems as an approach to managing this trade-off. Informally, the systems we propose set a system-wide prior for the quality of an incoming product, and subsequently the system updates that prior to a Bayesian posterior on quality based on user-generated ratings over time. Through calibrated simulations, we show that the strength of the prior directly determines the operating point on the identified trade-off: the stronger the prior, the more the marketplace discounts early ratings data (so individual producer fairness increases), but the slower the platform is in learning about true item quality (so efficiency suffers). Importantly, the prevailing method of ratings aggregation – displaying the sample mean of ratings – is an extreme point in this design space, that maximally prioritizes efficiency at the expense of producer fairness. Instead, by choosing a Bayesian rating system design with an appropriately set prior, a platform can be intentional about the consequential choice of a balance between efficiency and producer fairness.<br></div>



</p>
</li></ol>
    
  
    
    
    <h2> Other (workshops and technical reports)</h2>
    <ol class="bibliography"><li><p class="reallysmallbib">
<span id="fortiermultimodal2013year">&nbsp;2013&nbsp;</span>&nbsp;<strong>Multi-Modal, Multi-State, Real-Time Crew State Monitoring System</strong>





[<a href="javascript:;"onclick=showdropinfo('fortiermultimodal2013abstract')>abstract</a> | <a href="/files/pdfs/MultiModalMonitoring.pdf">pdf</a>]

<script>
  coloryear("fortiermultimodal2013", 2013, 2024);
</script>

<br><span id="fortiermultimodal2013">Kier Fortier, Nikhil Garg, and Elizabeth Pickering</span> <br>
 
  <i>NASA Glenn Research Center Research Report</i><br> 


<div id='fortiermultimodal2013abstract'  class="abstractcollapsed">I helped develop a Real-time, Multi-Modal, Crew State Monitoring System that integrates EEG, GSR, and HRV. I was in charge of overall design, EEG processing, machine learning, and multi-modal integration. I developed robust artifact rejection to detect and remove blinks and other artifacts from the EEG data; EEG feature extraction to represent blocks of data with frequency characteristics, statistical measures, and blink rate; and a machine learning classification system (through Support Vector Machines) that uses the features and characterizes data from a block of time as originating from either a state of rest or a state of concentration. I then integrated EEG and GSR features for joint classiﬁcation, and we demoed a end-to-end system that collected data from multiple sensors, extracted features, and trained and used the classiﬁer to predict subject state. The system successfully classiﬁed 80 percent of subject states.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="lewandowski_use_2015year">&nbsp;2015&nbsp;</span>&nbsp;<strong>Use of Electroencephalography and Galvanic Skin Response in the Prediction of an Attentive Cognitive State</strong>





[<a href="javascript:;"onclick=showdropinfo('lewandowski_use_2015abstract')>abstract</a> | <a href="/files/pdfs/HHPRSummitAbstract.pdf">pdf</a>]

<script>
  coloryear("lewandowski_use_2015", 2015, 2024);
</script>

<br><span id="lewandowski_use_2015">Beth Lewandowski, Kier Fortier, Nikhil Garg, Victor Rielly, Jeff Mackey, Tristan Hearn, Angela Harrivel, and Bradford Fenton</span> <br>
 Health and Human Performance Research Summit, Dayton, CO<br>
 


<div id='lewandowski_use_2015abstract'  class="abstractcollapsed">As part of an effort aimed at improving aviation safety, the Crew State Monitoring
               Element of the NASA Vehicle Systems Safety Technologies Project is developing a monitoring
               system capable of detecting cognitive states that may be associated with unsafe piloting
               conditions. The long term goal is a real-time, integrated system, that uses multiple physiological
               sensing modalities to detect multiple cognitive states with high accuracy, which can be used to
               help optimize human performance. Prior to realizing an integrated system, individual sensing
               modalities are being investigated, including the use of electroencephalographic (EEG) and
               galvanic skin response (GSR) signals, in the determination of an attentive or inattentive state.
               EEG and GSR data are collected during periods of rest and as subjects perform
               psychological tests including the psychomotor vigilance test, the Mackwork clock test and the
               attention network test. Subjects also perform tasks designed to simulate piloting tasks within the
               NASA multi-attribute task battery (MATB-II) program. The signals are filtered, the artifacts are
               rejected and the power spectral density (PSD) of the signals are found. Comparisons of the PSD
               between the rest and test blocks are made, along with the change in PSD over the time course of
               the blocks. Future work includes the collection of heart rate data and the investigation of heart
               rate variability as an additional measure to use in the prediction of attentive state, as well as the
               investigation of additional EEG signal processing methods such as source localization, multi-
               scale entropy and coherence measures. Preliminary results will be presented to highlight the
               methods used and to discuss our hypotheses.
               The challenges associated with realizing a real-time, accurate, multi-modal, cognitive
               state monitoring system are numerous. A discussion of some of the challenges will be provided,
               including real-time artifact rejection methods, quantification of inter- and intra-subject
               variability, determination of what information within the signals provides the best measurement
               of attention and determination of how information from the different modalities can be integrated
               to improve the overall accuracy of the system.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="garg_fair_2015year">&nbsp;2015&nbsp;</span>&nbsp;<strong>Fair Use and Innovation in Unlicensed Wireless Spectrum: LTE unlicensed and Wi-Fi in the 5 GHz unlicensed band</strong>





[<a href="/files/pdfs/Garg_Fair Use and Innovation in Unlicensed Wireless Spectrum.pdf">pdf</a>]

<script>
  coloryear("garg_fair_2015", 2015, 2024);
</script>

<br><span id="garg_fair_2015">Nikhil Garg</span> <br>
 IEEE-USA Journal of Technology and Public Policy<br>
 




</p>
</li>
<li><p class="reallysmallbib">
<span id="22dclassyear">&nbsp;2016&nbsp;</span>&nbsp;<strong>Transfer Learning: The Impact of Test Set Word Vectors, with Applications to Political Tweets</strong>





[<a href="javascript:;"onclick=showdropinfo('22dclassabstract')>abstract</a> | <a href="/files/pdfs/politweets.pdf">pdf</a>]

<script>
  coloryear("22dclass", 2016, 2024);
</script>

<br><span id="22dclass">Nikhil Garg and Arjun Seshadri</span> <br>
 
 


<div id='22dclassabstract'  class="abstractcollapsed">A major difficulty in applying deep learning in novel domains is the expense associated with acquiring sufficient training data. In this work, we extend literature in deep transfer learning by studying the role of initializing the embedding matrix with word vectors from GLoVe on a target dataset before training models with data from another domain. We study transfer learning on variants of four models (2 RNNs, a CNN, and an LSTM) and three datasets. We conclude that 1) the simple idea of initializing word vectors significantly and robustly improves transfer learning performance, 2) cross-domain learning occurs in fewer iterations than in-domain learning, considerably reduces train time, and 3) blending various out-of-domain datasets before training improves transfer learning. We then apply our models to a dataset of over 400k tweets by politicians, classifying sentiment and subjectivity vs. objectivity. This dataset was provided unlabeled, motivating an unsupervised and transfer learning approach. With transfer learning, we achieve reasonable performance on sentiment classification, but fail in classifying subjectivity vs. objectivity. <br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="gelauff_assu_2018year">&nbsp;2018&nbsp;</span>&nbsp;<strong>Comparing Voting Methods for Budget Decisions on the ASSU Ballot</strong>





[<a href="javascript:;"onclick=showdropinfo('gelauff_assu_2018abstract')>abstract</a> | <a href="/files/pdfs/ASSU_report.pdf">pdf</a>]

<script>
  coloryear("gelauff_assu_2018", 2018, 2024);
</script>

<br><span id="gelauff_assu_2018">Lodewijk Gelauff, Sukolsak Sakshuwong, Nikhil Garg, and Ashish Goel</span> <br>
 
 


<div id='gelauff_assu_2018abstract'  class="abstractcollapsed">During the 2018 Associated Students of Stanford University (ASSU; Stanford’s student body) election and annual grants process, the Stanford Crowdsourced Democracy Team (SCDT) ran a research ballot and survey to develop insights into voting behavior on the budget component of the ballot (annual grants) where multiple grant requests are considered. We provided voters with additional voting methods for the budget component, collected further insights through a survey and demonstrated the viability of the proposed workflow. Some of our findings are directly relevant to ASSU. Furthermore, the (appropriately anonymized) data gathered in this year’s research ballots is beneficial for research purposes. Overall, our platform and pipeline (PB Stanford) with post-validation of ballots functioned well on a large scale. In particular, the knapsack ballot mechanism shows promise in voter feedback.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="fishkindeliberation_19year">&nbsp;2019&nbsp;</span>&nbsp;<strong>Deliberative Democracy with the Online Deliberation Platform</strong>







<script>
  coloryear("fishkindeliberation_19", 2019, 2024);
</script>

<br><span id="fishkindeliberation_19">James Fishkin, Nikhil Garg, Lodewijk Gelauff, Ashish Goel, Kamesh Munagala, Sukolsak Sakshuwong, Alice Siu, and Sravya Yandamuri</span> <br>
 AAAI Conference on Human Computation and Crowdsourcing Demo Track<br>
 




</p>
</li></ol>
    
  
    
    
    <h2> Theses</h2>
    <ol class="bibliography"><li><p class="reallysmallbib">
<span id="garg_downlink_2015year">&nbsp;2015&nbsp;</span>&nbsp;<strong>Downlink and Uplink User Association in Dense Next-Generation Wireless Networks</strong>





[<a href="javascript:;"onclick=showdropinfo('garg_downlink_2015abstract')>abstract</a> | <a href="http://repositories.lib.utexas.edu/handle/2152/30074">official link</a>]

<script>
  coloryear("garg_downlink_2015", 2015, 2024);
</script>

<br><span id="garg_downlink_2015">Nikhil Garg</span> <br>
 
  <i>Bachelors Thesis, University of Texas at Austin.</i><br> 


<div id='garg_downlink_2015abstract'  class="abstractcollapsed">5G, the next-generation cellular network, must serve an aggregate data rate of
              1000 times that of current 4G networks while reducing data latency by a factor of ten. To meet these requirements, 5G networks will be far denser than existing networks, and small cells (femtocells and picocells) will augment network capacity. However, dense networks raise questions regarding interference, user association, and handoff between base stations. Where recent papers have demonstrated that interference from small cells will not be prohibitive under multi-slope path loss models, this thesis describes how the use of different path loss models affects the design of such dense, multi-tier networks. This thesis concludes that the gains realized by downlink biasing and uplink/downlink decoupling are strongly dependent on the path loss model assumed and the density differential between base station tiers. Furthermore, this thesis argues that the gains from uplink/downlink decoupling are reduced by a factor of 50% when optimal biasing for the downlink is used.<br></div>



</p>
</li>
<li><p class="reallysmallbib">
<span id="garg_phd_2020year">&nbsp;2020&nbsp;</span>&nbsp;<strong>Designing Marketplaces and Civic Engagement Platforms: Learning, Incentives, and Pricing</strong>





[<a href="javascript:;"onclick=showdropinfo('garg_phd_2020abstract')>abstract</a> | <a href="http://purl.stanford.edu/mf806mq4601">official link</a> | <a href="/files/papers/garg_dissertation_summary.pdf">summary</a> | <a href="https://www.youtube.com/watch?v=03IFmGa1ZQg">talk</a> | <a href="https://www.youtube.com/watch?v=rF5S8b80uwQ">short talk</a>]

<script>
  coloryear("garg_phd_2020", 2020, 2024);
</script>

<br><span id="garg_phd_2020">Nikhil Garg</span> <br>
 
  <i>PhD Dissertation, Stanford University<br>INFORMS George Dantzig Dissertation Award, 2020<br>ACM SIGecom dissertation award (Honorable mention), 2021</i><br> 


<div id='garg_phd_2020abstract'  class="abstractcollapsed"> Platforms increasingly mediate interactions between people: both helping us find work and transportation, and supporting our civic society through discussion and decision-making. Principled system design requires formalizing the platform’s objective and understanding the incentives, behavioral tendencies, and capabilities of participants; in turn, the design influences participant behavior. In this dissertation, I describe work designing platforms in two domains – two-sided marketplaces and civic engagement platforms – combining both theoretical and empirical analyses of such systems. First, I consider the design of surge pricing that is incentive compatible for drivers in ride-hailing platforms. Second, I tackle rating system inflation and design on online platforms. Finally, I study the design and deployment of systems for participatory budgeting. The work in this dissertation has informed deployments at Uber, a large online labor platform, and in participatory budgeting elections across the U.S.<br></div>



</p>
</li></ol>
    
  
</div>

<div id="Topic" class="tabcontent">
  
  
    
    
    <h2> Online Marketplaces</h2>
    <ol class="bibliography"><li>bibliography_topic</li>
<li>bibliography_topic</li>
<li>bibliography_topic</li></ol>
    
  
    
    
    <h2> Civic Engagement</h2>
    <ol class="bibliography"><li>bibliography_topic</li>
<li>bibliography_topic</li>
<li>bibliography_topic</li>
<li>bibliography_topic</li>
<li>bibliography_topic</li></ol>
    
  
    
    
    <h2> Algorithmic Fairness</h2>
    <ol class="bibliography"><li>bibliography_topic</li>
<li>bibliography_topic</li>
<li>bibliography_topic</li>
<li>bibliography_topic</li>
<li>bibliography_topic</li>
<li>bibliography_topic</li></ol>
    
  
    
    
    <h2> Natural Language Processing</h2>
    <ol class="bibliography"><li>bibliography_topic</li>
<li>bibliography_topic</li>
<li>bibliography_topic</li></ol>
    
  
    
    
    <h2> Wireless Communications and Signal Processing</h2>
    <ol class="bibliography"><li>bibliography_topic</li>
<li>bibliography_topic</li>
<li>bibliography_topic</li>
<li>bibliography_topic</li>
<li>bibliography_topic</li>
<li>bibliography_topic</li></ol>
    
  
    
    
  
</div>

<div id="Chronological" class="tabcontent">
  
  
  <h2> Working Papers</h2>
  <ol class="bibliography"><li><p class="reallysmallbib">
<span id="deshpandestrategies24typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Optimal Strategies in Ranked-Choice Voting</strong>
<!-- <strong>Optimal Strategies in Ranked-Choice Voting</strong> -->





[<a href="javascript:;"onclick=showdropinfo('deshpandestrategies24chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2407.13661">arxiv</a>]


<script>
  colortype("deshpandestrategies24", "working");
</script>

<br><span id="deshpandestrategies24">Sanyukta Deshpande, Nikhil Garg, and Sheldon Jacobson</span> <br>
 
 

 
 <div id='deshpandestrategies24chronabstract'  class="abstractcollapsed">Ranked Choice Voting (RCV) and Single Transferable Voting (STV) are widely valued; but are complex to understand due to intricate per-round vote transfers. Questions like determining how far a candidate is from winning or identifying effective election strategies are computationally challenging as minor changes in voter rankings can lead to significant ripple effects - for example, lending support to a losing candidate can prevent their votes from transferring to a more competitive opponent. We study optimal strategies - persuading voters to change their ballots or adding new voters - both algorithmically and theoretically. Algorithmically, we develop efficient methods to reduce election instances while maintaining optimization accuracy, effectively circumventing the computational complexity barrier. Theoretically, we analyze the effectiveness of strategies under both perfect and imperfect polling information. Our algorithmic approach applies to the ranked-choice polling data on the US 2024 Republican Primary, finding, for example, that several candidates would have been optimally served by boosting another candidate instead of themselves.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="milliweights23typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Choosing the Right Weights: Balancing Value, Strategy, and Noise in Recommender Systems</strong>
<!-- <strong>Choosing the Right Weights: Balancing Value, Strategy, and Noise in Recommender Systems</strong> -->





[<a href="javascript:;"onclick=showdropinfo('milliweights23chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2305.17428">arxiv</a>]


<script>
  colortype("milliweights23", "working");
</script>

<br><span id="milliweights23">Smitha Milli, Emma Pierson, and Nikhil Garg</span> <br>
 
 

 
 <div id='milliweights23chronabstract'  class="abstractcollapsed">Many recommender systems are based on optimizing a linear weighting of different user behaviors, such as clicks, likes, shares, etc. Though the choice of weights can have a significant impact, there is little formal study or guidance on how to choose them. We analyze the optimal choice of weights from the perspectives of both users and content producers who strategically respond to the weights. We consider three aspects of user behavior: value-faithfulness (how well a behavior indicates whether the user values the content), strategy-robustness (how hard it is for producers to manipulate the behavior), and noisiness (how much estimation error there is in predicting the behavior). Our theoretical results show that for users, upweighting more value-faithful and less noisy behaviors leads to higher utility, while for producers, upweighting more value-faithful and strategy-robust behaviors leads to higher welfare (and the impact of noise is non-monotonic). Finally, we discuss how our results can help system designers select weights in practice.
  <br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="pengmonoculture23typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Monoculture in Matching Markets</strong>
<!-- <strong>Monoculture in Matching Markets</strong> -->





[<a href="javascript:;"onclick=showdropinfo('pengmonoculture23chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2312.09841">arxiv</a>]


<script>
  colortype("pengmonoculture23", "working");
</script>

<br><span id="pengmonoculture23">Kenny Peng and Nikhil Garg</span> <br>
 
 

 
 <div id='pengmonoculture23chronabstract'  class="abstractcollapsed">Algorithmic monoculture arises when many decision-makers rely on the same algorithm to evaluate applicants. An emerging body of work investigates possible harms of this kind of homogeneity, but has been limited by the challenge of incorporating market effects in which the preferences and behavior of many applicants and decision-makers jointly interact to determine outcomes.
    
  Addressing this challenge, we introduce a tractable theoretical model of algorithmic monoculture in a two-sided matching market with many participants. We use the model to analyze outcomes under monoculture (when decision-makers all evaluate applicants using a common algorithm) and under polyculture (when decision-makers evaluate applicants independently). All else equal, monoculture (1) selects less-preferred applicants when noise is well-behaved, (2) matches more applicants to their top choice, though individual applicants may be worse off depending on their value to decision-makers and risk tolerance, and (3) is more robust to disparities in the number of applications submitted.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="admissionsmlrace24typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Algorithms for College Admissions Decision Support: Impacts of Policy Change and Inherent Variability</strong>
<!-- <strong>Algorithms for College Admissions Decision Support: Impacts of Policy Change and Inherent Variability</strong> -->





[<a href="javascript:;"onclick=showdropinfo('admissionsmlrace24chronabstract')>abstract</a> | <a href="http://arxiv.org/abs/2407.11199">arxiv</a>]


<script>
  colortype("admissionsmlrace24", "working");
</script>

<br><span id="admissionsmlrace24">Jinsook Lee, Emma Harvey, Joyce Zhou, Nikhil Garg, Thorsten Joachims, and René Kizilcec</span> <br>
 
 

 
 <div id='admissionsmlrace24chronabstract'  class="abstractcollapsed">Each year, selective American colleges sort through tens of thousands of applications to identify a first-year class that displays both academic merit and diversity. In the 2023-2024 admissions cycle, these colleges faced unprecedented challenges to doing so. First, the number of applications has been steadily growing year-over-year. Second, test-optional policies that have remained in place since the COVID-19 pandemic limit access to key information that has historically been predictive of academic success. Most recently, longstanding debates over affirmative action culminated in the Supreme Court banning race-conscious admissions. Colleges have explored machine learning (ML) models to address the issues of scale and missing test scores, often via ranking algorithms intended to allow human reviewers to focus attention on ‘top’ applicants. However, the Court’s ruling will force changes to these models, which were previously able to consider race as a factor in ranking. There is currently a poor understanding of how these mandated changes will shape applicant ranking algorithms, and, by extension, admitted classes. We seek to address this by quantifying the impact of different admission policies on the applications prioritized for review. We show that removing race data from a previously developed applicant ranking algorithm reduces the diversity of the top-ranked pool of applicants without meaningfully increasing the academic merit of that pool. We contextualize this impact by showing that excluding data on applicant race has a greater impact than excluding other potentially informative variables like intended majors. Finally, we measure the impact of policy change on individuals by comparing the arbitrariness in applicant rank attributable to policy change to the arbitrariness attributable to randomness (i.e., how much an applicant’s rank changes across models that use the same policy but are trained on bootstrapped samples from the same dataset). We find that any given policy has a high degree of arbitrariness (i.e. at most 9% of applicants are consistently ranked in the top 20%), and that removing race data from the ranking algorithm increases arbitrariness in outcomes for most applicants.<br></div>
 

 
</p>
 

</li></ol>
  

  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
    <h2> 2025 </h2>
    <ol class="bibliography"><li><p class="reallysmallbib">
<span id="producerfairness23typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Balancing Producer Fairness and Efficiency via Bayesian Rating System Design</strong>
<!-- <strong>Balancing Producer Fairness and Efficiency via Bayesian Rating System Design</strong> -->





[<a href="javascript:;"onclick=showdropinfo('producerfairness23chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2207.04369">arxiv</a>]


<script>
  colortype("producerfairness23", "inproceedings");
</script>

<br><span id="producerfairness23">Thomas Ma, Michael Bernstein, Ramesh Johari, and Nikhil Garg</span> <br>
 International AAAI Conference on Web and Social Media (ICWSM ‘25)<br>
 

 
 <div id='producerfairness23chronabstract'  class="abstractcollapsed">Online marketplaces use rating systems to promote discovery of high quality products. However, these systems also lead to high variance in producers’ economic outcomes: a new producer who sells high-quality items, may, by luck, receive one low rating early on, negatively impacting their popularity with future customers. We investigate the design of rating systems that balance the goals of identifying high quality products ("efficiency") and minimizing the variance in economic outcomes of producers of similar quality (individual "producer fairness"). We observe that there is a trade-off between these two goals: rating systems that promote efficiency are necessarily less individually fair to producers. We introduce Bayesian rating systems as an approach to managing this trade-off. Informally, the systems we propose set a system-wide prior for the quality of an incoming product, and subsequently the system updates that prior to a Bayesian posterior on quality based on user-generated ratings over time. Through calibrated simulations, we show that the strength of the prior directly determines the operating point on the identified trade-off: the stronger the prior, the more the marketplace discounts early ratings data (so individual producer fairness increases), but the slower the platform is in learning about true item quality (so efficiency suffers). Importantly, the prevailing method of ratings aggregation – displaying the sample mean of ratings – is an extreme point in this design space, that maximally prioritizes efficiency at the expense of producer fairness. Instead, by choosing a Bayesian rating system design with an appropriately set prior, a platform can be intentional about the consequential choice of a balance between efficiency and producer fairness.<br></div>
 

 
</p>
 

</li></ol>
    
  
    
    
    <h2> 2024 </h2>
    <ol class="bibliography"><li><p class="reallysmallbib">
<span id="networksunder23typecount">&nbsp;&nbsp;</span>&nbsp;<strong>A Bayesian Spatial Model to Correct Under-Reporting in Urban Crowdsourcing</strong>
<!-- <strong>A Bayesian Spatial Model to Correct Under-Reporting in Urban Crowdsourcing</strong> -->





[<a href="javascript:;"onclick=showdropinfo('networksunder23chronabstract')>abstract</a> | <a href="https://doi.org/10.1609/aaai.v38i20.30190">official link</a> | <a href="https://arxiv.org/abs/2312.11754">arxiv</a> | <a href="https://github.com/gsagostini/networks_underreporting/">code & data</a>]


<script>
  colortype("networksunder23", "inproceedings");
</script>

<br><span id="networksunder23">Gabriel Agostini, Emma Pierson, and Nikhil Garg</span> <br>
 AAAI Conference on Artificial Intelligence (AAAI‘24) (Oral Presentation)<br>
 

 
 <div id='networksunder23chronabstract'  class="abstractcollapsed">Decision-makers often observe the occurrence of events through a reporting process. City governments, for example, rely on resident reports to find and then resolve urban infrastructural problems such as fallen street trees, flooded basements, or rat infestations. Without additional assumptions, there is no way to distinguish events that occur but are not reported from events that truly did not occur–a fundamental problem in settings with positive-unlabeled data. Because disparities in reporting rates correlate with resident demographics, addressing incidents only on the basis of reports leads to systematic neglect in neighborhoods that are less likely to report events. We show how to overcome this challenge by leveraging the fact that events are \textitspatially correlated. Our framework uses a Bayesian spatial latent variable model to infer event occurrence probabilities and applies it to storm-induced flooding reports in New York City, further pooling results across multiple storms. We show that a model accounting for under-reporting and spatial correlation predicts future reports more accurately than other models, and further induces a more equitable set of inspections: its allocations better reflect the population and provide equitable service to non-white and lower-income areas. This finding reflects heterogeneous reporting behavior learned by the model: reporting rates are higher in Census tracts with higher populations, proportions of white residents, and proportions of owner-occupied households. Our work lays the groundwork for more equitable proactive government services, even with disparate reporting behavior.  <br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="library24typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Identifying and Addressing Disparities in Public Libraries with Bayesian Latent Variable Modeling</strong>
<!-- <strong>Identifying and Addressing Disparities in Public Libraries with Bayesian Latent Variable Modeling</strong> -->





[<a href="javascript:;"onclick=showdropinfo('library24chronabstract')>abstract</a> | <a href="https://doi.org/10.1609/aaai.v38i20.30231">official link</a> | <a href="https://github.com/ZhiLiu724/library_disparities">code & data</a>]


<script>
  colortype("library24", "inproceedings");
</script>

<br><span id="library24">Zhi Liu, Sarah Rankin, and Nikhil Garg</span> <br>
 AAAI Conference on Artificial Intelligence (AAAI‘24)<br>
 

 
 <div id='library24chronabstract'  class="abstractcollapsed">Public libraries are an essential public good. We ask: are urban library systems providing equitable service to all residents, in terms of the books they have access to and check out? If not, what causes disparities: heterogeneous book collections, resident behavior and access, and/or operational policies? Existing methods leverage only system-level outcome data (such as overall checkouts per branch), and so cannot distinguish between these factors. As a result, it is difficult to use their results to guide interventions to increase equitable access. We propose a Bayesian framework to characterize book checkout behavior across multiple branches of a library system, learning heterogeneous book popularity, overall branch demand, and usage of the online hold system, while controlling for book availability.

In collaboration with the New York Public Library, we apply our framework to granular data consisting of over 400,000 checkouts during 2022. We first show that our model significantly out-performs baseline methods in predicting checkouts at the book-branch level. Next, we study spatial and socioeconomic disparities. We show that disparities are largely driven by disparate use of the online holds system, which allows library patrons to receive books from any other branch through an online portal. This system thus leads to a large outflow of popular books from branches in lower income neighborhoods to those in high income ones. Finally, we illustrate the use of our model and insights to quantify the impact of potential interventions, such as changing how books are internally routed between branches to fulfill hold requests.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="missingdomaintypecount">&nbsp;&nbsp;</span>&nbsp;<strong>Domain constraints improve risk prediction when outcome data is missing</strong>
<!-- <strong>Domain constraints improve risk prediction when outcome data is missing</strong> -->





[<a href="javascript:;"onclick=showdropinfo('missingdomainchronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2312.03878">arxiv</a>]


<script>
  colortype("missingdomain", "inproceedings");
</script>

<br><span id="missingdomain">Sidhika Balachandar, Nikhil Garg, and Emma Pierson</span> <br>
 International Conference on Learning Representations (ICLR‘24)<br>
 

 
 <div id='missingdomainchronabstract'  class="abstractcollapsed">Machine learning models are often trained to predict the outcome resulting from a human decision. For example, if a doctor decides to test a patient for disease, will the patient test positive? A challenge is that the human decision censors the outcome data: we only observe test outcomes for patients doctors historically tested. Untested patients, for whom outcomes are unobserved, may differ from tested patients along observed and unobserved dimensions. We propose a Bayesian model class which captures this setting. The purpose of the model is to accurately estimate risk for both tested and untested patients. Estimating this model is challenging due to the wide range of possibilities for untested patients. To address this, we propose two domain constraints which are plausible in health settings: a prevalence constraint, where the overall disease prevalence is known, and an expertise constraint, where the human decision-maker deviates from purely risk-based decision-making only along a constrained feature set. We show theoretically and on synthetic data that domain constraints improve parameter inference. We apply our model to a case study of cancer risk prediction, showing that the model’s inferred risk predicts cancer diagnoses, its inferred testing policy captures known public health policies, and it can identify suboptimalities in test allocation. Though our case study is in healthcare, our analysis reveals a general class of domain constraints which can improve model estimation in many settings.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="pengdiverseaccuracy23typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Reconciling the accuracy-diversity trade-off in recommendations</strong>
<!-- <strong>Reconciling the accuracy-diversity trade-off in recommendations</strong> -->





[<a href="javascript:;"onclick=showdropinfo('pengdiverseaccuracy23chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2307.15142.pdf">arxiv</a> | <a href="https://dl.acm.org/doi/10.1145/3589334.3645625">official link</a>]


<script>
  colortype("pengdiverseaccuracy23", "inproceedings");
</script>

<br><span id="pengdiverseaccuracy23">Kenny Peng, Manish Raghavan, Emma Pierson, Jon Kleinberg, and Nikhil Garg</span> <br>
 The ACM Web Conference (WWW‘24) (Oral Presentation)<br>
 

 
 <div id='pengdiverseaccuracy23chronabstract'  class="abstractcollapsed">In recommendation settings, there is an apparent trade-off between the goals of accuracy (to recommmend items a user is most likely to want) and diversity (to recommend items representing a range of categories). As such, real-world recommender systems often explicitly incorporate diversity separately from accuracy. This approach, however, leaves a basic question unanswered: Why is there a trade-off in the first place? We analyze a stylized model of recommendations reconciling this trade-off. Accounting for a user’s capacity constraints (users do not typically make use of all the items that are recommended to them), optimal recommendations in our model are inherently diverse. Thus, accuracy and diversity appear misaligned because traditional accuracy metrics do not consider capacity constraints. Our model yields precise and interpretable characterizations of diversity in different settings, giving practical insights into the design of diverse recommendations.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="argmaxdisparities24typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Addressing Discretization-Induced Bias in Demographic Prediction</strong>
<!-- <strong>Addressing Discretization-Induced Bias in Demographic Prediction</strong> -->





[<a href="javascript:;"onclick=showdropinfo('argmaxdisparities24chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2405.16762">arxiv</a>]


<script>
  colortype("argmaxdisparities24", "inproceedings");
</script>

<br><span id="argmaxdisparities24">Evan Dong, Aaron Schein, Yixin Wang, and Nikhil Garg</span> <br>
 ACM Conference on Fairness, Accountability, and Transparency (FAccT‘24)<br>
 

 
 <div id='argmaxdisparities24chronabstract'  class="abstractcollapsed">Racial and other demographic imputation is necessary for many applications, especially in auditing disparities and outreach targeting in political campaigns. The canonical approach is to construct continuous predictions – e.g., based on name and geography – and then to discretize the predictions by selecting the most likely class (argmax). We study how this practice produces discretization bias. In particular, we show that argmax labeling, as used by a prominent commercial voter file vendor to impute race/ethnicity, results in a substantial under-count of African-American voters, e.g., by 28.2% points in North Carolina. This bias can have substantial implications in downstream tasks that use such labels.
  We then introduce a joint optimization approach – and a tractable data-driven thresholding heuristic – that can eliminate this bias, with negligible individual-level accuracy loss. Finally, we theoretically analyze discretization bias, show that calibrated continuous models are insufficient to eliminate it, and that an approach such as ours is necessary. Broadly, we warn researchers and practitioners against discretizing continuous demographic predictions without considering downstream consequences.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="llmhackathaon23typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Large language models shape and are shaped by society: A survey of arXiv publication patterns</strong>
<!-- <strong>Large language models shape and are shaped by society: A survey of arXiv publication patterns</strong> -->





[<a href="javascript:;"onclick=showdropinfo('llmhackathaon23chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2307.10700">arxiv</a>]


<script>
  colortype("llmhackathaon23", "inproceedings");
</script>

<br><span id="llmhackathaon23">Rajiv Movva, Sidhika Balachandar, Kenny Peng, Gabriel Agostini, Nikhil Garg, and Emma Pierson</span> <br>
 The North American Chapter of the Association for Computational Linguistics (NAACL‘24)<br>
 

 
 <div id='llmhackathaon23chronabstract'  class="abstractcollapsed">There has been a steep recent increase in the number of large language model (LLM) papers, producing a dramatic shift in the scientific landscape which remains largely undocumented through bibliometric analysis. Here, we analyze 388K papers posted on the CS and Stat arXivs, focusing on changes in publication patterns in 2023 vs. 2018-2022. We analyze how the proportion of LLM papers is increasing; the LLM-related topics receiving the most attention; the authors writing LLM papers; how authors’ research topics correlate with their backgrounds; the factors distinguishing highly cited LLM papers; and the patterns of international collaboration. We show that LLM research increasingly focuses on societal impacts: there has been an 18x increase in the proportion of LLM-related papers on the Computers and Society sub-arXiv, and authors newly publishing on LLMs are more likely to focus on applications and societal impacts than more experienced authors. LLM research is also shaped by social dynamics: we document gender and academic/industry disparities in the topics LLM authors focus on, and a US/China schism in the collaboration network. Overall, our analysis documents the profound ways in which LLM research both shapes and is shaped by society, attesting to the necessity of sociotechnical lenses.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="pengwisdomnoisy24typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Wisdom and Foolishness of Noisy Matching Markets  </strong>
<!-- <strong>Wisdom and Foolishness of Noisy Matching Markets  </strong> -->





[<a href="javascript:;"onclick=showdropinfo('pengwisdomnoisy24chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2402.16771">arxiv</a>]


<script>
  colortype("pengwisdomnoisy24", "inproceedings");
</script>

<br><span id="pengwisdomnoisy24">Kenny Peng and Nikhil Garg</span> <br>
 ACM Conference on Economics and Computation (EC‘24)<br>
 

 
 <div id='pengwisdomnoisy24chronabstract'  class="abstractcollapsed">We consider a many-to-one matching market where colleges share true preferences over students but make decisions using only independent noisy rankings. Each student has a \textittrue value v, but each college c ranks the student according to an independently drawn \textitestimated value v + X_c for X_c∼\DD. We ask a basic question about the resulting stable matching: How noisy is the set of matched students? Two striking effects can occur in large markets (i.e., with a continuum of students and a large number of colleges). When \DD is light-tailed, noise is fully attenuated: only the highest-value students are matched. When \DD is long-tailed, noise is fully amplified: students are matched uniformly at random. These results hold for any distribution of student preferences over colleges, and extend to when only subsets of colleges agree on true student valuations instead of the entire market. More broadly, our framework provides a tractable approach to analyze implications of imperfect preference formation in large markets.
  <br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="LiuSLA24typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Redesigning Service Level Agreements: Equity and Efficiency in City Government Operations</strong>
<!-- <strong>Redesigning Service Level Agreements: Equity and Efficiency in City Government Operations</strong> -->








<script>
  colortype("LiuSLA24", "inproceedings");
</script>

<br><span id="LiuSLA24">Zhi Liu and Nikhil Garg</span> <br>
 ACM Conference on Economics and Computation (EC‘24)<br>
 

 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="Congestion24typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Equitable Congestion Pricing under the Markovian Traffic Model: An Application to Bogota</strong>
<!-- <strong>Equitable Congestion Pricing under the Markovian Traffic Model: An Application to Bogota</strong> -->





[<a href="javascript:;"onclick=showdropinfo('Congestion24chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2407.05035">arxiv</a>]


<script>
  colortype("Congestion24", "inproceedings");
</script>

<br><span id="Congestion24">Alfredo Torrico, Natthawut Boonsiriphatthanajaroen, Nikhil Garg, Andrea Lodi, and Hugo Mainguy</span> <br>
 ACM Conference on Economics and Computation (EC‘24)<br>
 

 
 <div id='Congestion24chronabstract'  class="abstractcollapsed">Congestion pricing is used to raise revenues and reduce traffic and pollution. However, people have heterogeneous spatial demand patterns and willingness (or ability) to pay tolls, and so pricing may have substantial equity implications. We develop a data-driven approach to design congestion pricing given policymakers’ equity and efficiency objectives. First, algorithmically, we extend the Markovian traffic equilibrium setting introduced by Baillon & Cominetti (2008) to model heterogeneous populations and incorporate prices and outside options such as public transit. Second, we empirically evaluate various pricing schemes using data collected by an industry partner in the city of Bogota, one of the most congested cities in the world. We find that pricing personalized to each economic stratum can be substantially more efficient and equitable than uniform pricing; however, non-personalized but area-based pricing can recover much of the gap.
<br></div>
 

 
</p>
 

</li></ol>
    
  
    
    
    <h2> 2023 </h2>
    <ol class="bibliography"><li><p class="reallysmallbib">
<span id="racedisparities23typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Coarse race data conceals disparities in clinical risk score performance
  </strong>
<!-- <strong>Coarse race data conceals disparities in clinical risk score performance
  </strong> -->





[<a href="javascript:;"onclick=showdropinfo('racedisparities23chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2304.09270">arxiv</a>]


<script>
  colortype("racedisparities23", "inproceedings");
</script>

<br><span id="racedisparities23">Rajiv Movva, Divya Shanmugam, Kaihua Hou, Priya Pathak, John Guttag, Nikhil Garg, and Emma Pierson</span> <br>
 Machine Learning for Healthcare (ML4HC)<br>
 

 
 <div id='racedisparities23chronabstract'  class="abstractcollapsed">Healthcare data in the United States often records only a patient’s coarse race group: for example, both Indian and Chinese patients are typically coded as “Asian.” It is unknown, however, whether this coarse coding conceals meaningful disparities in the performance of clinical risk scores across granular race groups. Here we show that it does. Using data from 418K emergency department visits, we assess clinical risk score performance disparities across granular race groups for three outcomes, five risk scores, and four performance metrics. Across outcomes and metrics, we show that there are significant granular disparities in performance within coarse race categories. In fact, variation in performance metrics within coarse groups often exceeds the variation between coarse groups. We explore why these disparities arise, finding that outcome rates, feature distributions, and the relationships between features and outcomes all vary significantly across granular race categories. Our results suggest that healthcare providers, hospital systems, and machine learning researchers should strive to collect, release, and use granular race data in place of coarse race data, and that existing analyses may significantly underestimate racial disparities in performance.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="recsyspiki23typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Interface Design to Mitigate Inflation in Recommender Systems
  </strong>
<!-- <strong>Interface Design to Mitigate Inflation in Recommender Systems
  </strong> -->





[<a href="javascript:;"onclick=showdropinfo('recsyspiki23chronabstract')>abstract</a> | <a href="https://doi.org/10.1145/3604915.3608846">official link</a>]


<script>
  colortype("recsyspiki23", "inproceedings");
</script>

<br><span id="recsyspiki23">Rana Shahout, Yehonatan Peisakhovsky, Sasha Stoikov, and Nikhil Garg</span> <br>
 ACM Conference on Recommender Systems (RecSys ’23 Short paper)<br>
 

 
 <div id='recsyspiki23chronabstract'  class="abstractcollapsed">Recommendation systems rely on user-provided data to learn about item quality and provide personalized recommendations. An implicit assumption when aggregating ratings into item quality is that ratings are strong indicators of item quality. In this work, we test this assumption using data collected from a music discovery application. Our study focuses on two factors that cause rating inflation: heterogeneous user rating behavior and the dynamics of personalized recommendations.
  We show that user rating behavior is substantially varies by user, leading to item quality estimates that reflect the users who rated an item more than the item quality itself. Additionally, items that are more likely to be shown via personalized recommendations can experience a substantial increase in their exposure and potential bias toward them. To mitigate these effects, we analyze the results of a randomized controlled trial in which the rating interface was modified. The test resulted in a substantial improvement in user rating behavior and a reduction in item quality inflation. These findings highlight the importance of carefully considering the assumptions underlying recommendation systems and designing interfaces that encourage accurate rating behavior.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="vincefield23typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Faster Information for Effective LTC Discharge, A Field Study in Adult Foster Care</strong>
<!-- <strong>Faster Information for Effective LTC Discharge, A Field Study in Adult Foster Care</strong> -->





[<a href="javascript:;"onclick=showdropinfo('vincefield23chronabstract')>abstract</a>]


<script>
  colortype("vincefield23", "inproceedings");
</script>

<br><span id="vincefield23">Vince Bartle, Nicola Dell, and Nikhil Garg</span> <br>
 ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization (EAAMO‘23)<br>
 

 
 <div id='vincefield23chronabstract'  class="abstractcollapsed">A growing proportion of the population is elderly. With this aging population, an increasing challenge is placing patients into adult foster care facilities, which are small long-term care nursing facilities. A key challenge is the dynamic matching process between hospital discharge coordinators looking to place patients, and facilities looking for residents. This paper describes the design and implementation of a 12 month deployment to support decision making among a team of 6 social workers assisting in the discharge of 107 long term care patients across 1,047 potential care facilities. Our system collected vacancy and capability data from facilities over time through conversational SMS. We then process the data to provide call recommendations as to which homes might be best for social workers to contact. We show that our system had sustained engagement over the duration of the deployment and provide evidence of the impact that timely, accurate information has on easing long-term care patient matching. Overall, we demonstrate that platforms for information exchange – even absent algorithmic recommendation or matching – can increase matching efficacy. We further provide lessons for designing information collection systems and provisioning platforms in similar contexts.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="jagadeesan23typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Supply-Side Equilibria in Recommender Systems</strong>
<!-- <strong>Supply-Side Equilibria in Recommender Systems</strong> -->





[<a href="javascript:;"onclick=showdropinfo('jagadeesan23chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2206.13489">arxiv</a>]


<script>
  colortype("jagadeesan23", "inproceedings");
</script>

<br><span id="jagadeesan23">Meena Jagadeesan, Nikhil Garg, and Jacob Steinhardt</span> <br>
 Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS ‘23)<br>
 

 
 <div id='jagadeesan23chronabstract'  class="abstractcollapsed">Digital recommender systems such as Spotify and Netflix affect not only consumer behavior but also producer incentives: producers seek to supply content that will be recommended by the system. But what content will be produced? In this paper, we investigate the supply-side equilibria in content recommender systems. We model users and content as D-dimensional vectors, and recommend the content that has the highest dot product with each user. The main features of our model are that the producer decision space is high-dimensional and the user base is heterogeneous. This gives rise to new qualitative phenomena at equilibrium: First, the formation of genres, where producers specialize to compete for subsets of users. Using a duality argument, we derive necessary and sufficient conditions for this specialization to occur. Second, we show that producers can achieve positive profit at equilibrium, which is typically impossible under perfect competition. We derive sufficient conditions for this to occur, and show it is closely connected to specialization of content. In both results, the interplay between the geometry of the users and the structure of producer costs influences the structure of the supply-side equilibria. At a conceptual level, our work serves as a starting point to investigate how recommender systems shape supply-side competition between producers.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="liuequitycrowdsourcing22typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Quantifying Spatial Under-reporting Disparities in Resident Crowdsourcing</strong>
<!-- <strong>Quantifying Spatial Under-reporting Disparities in Resident Crowdsourcing</strong> -->





[<a href="javascript:;"onclick=showdropinfo('liuequitycrowdsourcing22chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2204.08620">arxiv</a> | <a href="https://www.nature.com/articles/s43588-023-00572-6">official link</a> | <a href="https://www.youtube.com/watch?v=Ffhj3aW2gSU&t">talk</a> | <a href="https://github.com/nikhgarg/spatial_underreporting_crowdsourcing">code & data</a>]


<script>
  colortype("liuequitycrowdsourcing22", "article");
</script>

<br><span id="liuequitycrowdsourcing22">Zhi Liu, Uma Bhandaram, and Nikhil Garg</span> <br>
 Nature Computational Science<br>
  <i>Conference version published in ACM Conference on Economics and Computation (EC‘22), titled “Equity in Resident Crowdsourcing: Measuring Under-reporting without Ground Truth Data”<br><font color="red">Media</font>: <a href="https://news.cornell.edu/stories/2023/12/method-may-improve-cities-responses-resident-service-calls">Cornell News</a>.</i><br> 

 
 <div id='liuequitycrowdsourcing22chronabstract'  class="abstractcollapsed">
    Modern city governance relies heavily on crowdsourcing to identify
    problems such as downed trees and power lines. A major concern is that
    residents do not report problems at the same rates, with heterogeneous
    reporting delays directly translating to downstream disparities in how
    quickly incidents can be addressed. Here we develop a method to identify
    reporting delays without using external ground-truth data. Our insight is
    that the rates at which duplicate reports are made about the same incident
    can be leveraged to disambiguate whether an incident has occurred by
    investigating its reporting rate once it has occurred. We apply our method to
    over 100,000 resident reports made in New York City and to over 900,000
    reports made in Chicago, finding that there are substantial spatial and
    socioeconomic disparities in how quickly incidents are reported. We further
    validate our methods using external data and demonstrate how estimating
    reporting delays leads to practical insights and interventions for a more
    equitable, efficient government service.<br></div>
 

 
</p>
 

</li></ol>
    
  
    
    
    <h2> 2022 </h2>
    <ol class="bibliography"><li><p class="reallysmallbib">
<span id="liusrategicranking21typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Strategic Ranking</strong>
<!-- <strong>Strategic Ranking</strong> -->





[<a href="javascript:;"onclick=showdropinfo('liusrategicranking21chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2109.08240">arxiv</a>]


<script>
  colortype("liusrategicranking21", "inproceedings");
</script>

<br><span id="liusrategicranking21">Lydia Liu, Nikhil Garg, and Christian Borgs</span> <br>
 International Conference on Artificial Intelligence and Statistics (AISTATS‘22)<br>
 

 
 <div id='liusrategicranking21chronabstract'  class="abstractcollapsed">
                 Strategic classification studies the design of a classifier robust to the manipulation of input by strategic individuals. However, the existing literature does not consider the effect of competition among individuals as induced by the algorithm design. Motivated by constrained allocation settings such as college admissions, we introduce strategic ranking, in which the (designed) individual reward depends on an applicant’s post-effort rank in a measurement of interest. Our results illustrate how competition among applicants affects the resulting equilibria and model insights. We analyze how various ranking reward designs trade off applicant, school, and societal utility and in particular how ranking design can counter inequities arising from disparate access to resources to improve one’s measured score: We find that randomization in the ranking reward design can mitigate two measures of disparate impact, welfare gap and access, whereas non-randomization may induce a high level of competition that systematically excludes a disadvantaged group.
                 <br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="patro2022fairtypecount">&nbsp;&nbsp;</span>&nbsp;<strong>Fair ranking: a critical review, challenges, and future directions</strong>
<!-- <strong>Fair ranking: a critical review, challenges, and future directions</strong> -->





[<a href="javascript:;"onclick=showdropinfo('patro2022fairchronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2201.12662">arxiv</a> | <a href="https://doi.org/10.1145/3531146.3533238">official link</a>]


<script>
  colortype("patro2022fair", "inproceedings");
</script>

<br><span id="patro2022fair">Gourab K Patro, Lorenzo Porcaro, Laura Mitchell, Qiuyue Zhang, Meike Zehlike, and Nikhil Garg</span> <br>
 ACM Conference on Fairness, Accountability, and Transparency (FAccT‘22)<br>
  <i>This work was written as part of a distributed, student-led working group of <a href="https://www.md4sg.com/">Mechanism Design for Social Good</a></i><br> 

 
 <div id='patro2022fairchronabstract'  class="abstractcollapsed">
    Ranking, recommendation, and retrieval systems are widely used in online platforms and other societal systems, including e-commerce, media-streaming, admissions, gig platforms, and hiring. In the recent past, a large "fair ranking" research literature has been developed around making these systems fair to the individuals, providers, or content that are being ranked. Most of this literature defines fairness for a single instance of retrieval, or as a simple additive notion for multiple instances of retrievals over time. This work provides a critical overview of this literature, detailing the often context-specific concerns that such an approach misses: the gap between high ranking placements and true provider utility, spillovers and compounding effects over time, induced strategic incentives, and the effect of statistical uncertainty. We then provide a path forward for a more holistic and impact-oriented fair ranking research agenda, including methodological lessons from other fields and the role of the broader stakeholder community in overcoming data bottlenecks and designing effective regulatory environments.
    <br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="ZPTrucks22typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Trucks Don’t Mean Trump: Diagnosing Human Error in Image Analysis</strong>
<!-- <strong>Trucks Don’t Mean Trump: Diagnosing Human Error in Image Analysis</strong> -->





[<a href="javascript:;"onclick=showdropinfo('ZPTrucks22chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2205.07333">arxiv</a> | <a href="doi.acm.org?doi=3531146.3533145">official link</a>]


<script>
  colortype("ZPTrucks22", "inproceedings");
</script>

<br><span id="ZPTrucks22">J.D. Zamfirescu-Pereira, Jerry Chen, Emily Wen, Allison Koenecke, Nikhil Garg, and Emma Pierson</span> <br>
 ACM Conference on Fairness, Accountability, and Transparency (FAccT‘22)<br>
  <i><font color="red">Media</font>: <a href="https://cis.cornell.edu/do-trucks-mean-trump-ai-shows-how-humans-misjudge-images">Cornell News</a>.</i><br> 

 
 <div id='ZPTrucks22chronabstract'  class="abstractcollapsed">Algorithms provide powerful tools for detecting and dissecting human bias and error. Here, we develop machine learning methods to to analyze how humans err in a particular high-stakes task: image interpretation. We leverage a unique dataset of 16,135,392 human predictions of whether a neighborhood voted for Donald Trump or Joe Biden in the 2020 US election, based on a Google Street View image. We show that by training a machine learning estimator of the Bayes optimal decision for each image, we can provide an actionable decomposition of human error into bias, variance, and noise terms, and further identify specific features (like pickup trucks) which lead humans astray. Our methods can be applied to ensure that human-in-the-loop decision-making is accurate and fair and are also applicable to black-box algorithmic systems.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="garggerrysocialchoice21typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Combatting Gerrymandering with Social Choice: the Design of Multi-member Districts</strong>
<!-- <strong>Combatting Gerrymandering with Social Choice: the Design of Multi-member Districts</strong> -->





[<a href="javascript:;"onclick=showdropinfo('garggerrysocialchoice21chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2107.07083">arxiv</a>]


<script>
  colortype("garggerrysocialchoice21", "inproceedings");
</script>

<br><span id="garggerrysocialchoice21">Nikhil Garg, Wes Gurnee, David Rothschild, and David Shmoys</span> <br>
 ACM Conference on Economics and Computation (EC‘22)<br>
  <i><font color="red">Media</font>: <a href="https://news.cornell.edu/stories/2021/09/ranked-choice-multimember-districts-blunts-gerrymandering">Cornell Chronicle</a>.</i><br> 

 
 <div id='garggerrysocialchoice21chronabstract'  class="abstractcollapsed">
                 Every representative democracy must specify a mechanism under which voters choose their representatives. The most common mechanism in the United States – winner-take-all single-member districts – both enables substantial partisan gerrymandering and constrains‘fair’ redistricting, preventing proportional representation in legislatures. We study the design of multi-member districts (MMDs), in which each district elects multiple representatives, potentially through a non-winner-takes-all voting rule. We carry out large-scale analyses for the U.S. House of Representatives under MMDs with different social choice functions, under algorithmically generated maps optimized for either partisan benefit or proportionality. Doing so requires efficiently incorporating predicted partisan outcomes – under various multi-winner social choice functions – into an algorithm that optimizes over an ensemble of maps. We find that with three-member districts using Single Transferable Vote, fairness-minded independent commissions would be able to achieve proportional outcomes in every state up to rounding, and advantage-seeking partisans would have their power to gerrymander significantly curtailed. Simultaneously, such districts would preserve geographic cohesion, an arguably important aspect of representative democracies. In the process, we open up a rich research agenda at the intersection of social choice and computational redistricting.  <br></div>
 

 
</p>
 

</li></ol>
    
  
    
    
    <h2> 2021 </h2>
    <ol class="bibliography"><li><p class="reallysmallbib">
<span id="gargbiastest_20typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Dropping Standardized Testing for Admissions: Differential Variance and Access</strong>
<!-- <strong>Dropping Standardized Testing for Admissions: Differential Variance and Access</strong> -->





[<a href="javascript:;"onclick=showdropinfo('gargbiastest_20chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2010.04396">arxiv</a>]


<script>
  colortype("gargbiastest_20", "inproceedings");
</script>

<br><span id="gargbiastest_20">Nikhil Garg, Hannah Li, and Faidra Monachou</span> <br>
 ACM Conference on Fairness, Accountability, and Transparency (FAccT‘21)<br>
  <i>Also appeared in EAAMO‘21, with Best Student Paper Award<br>Appeared in the 2021 NBER Decentralization Conference</i><br> 

 
 <div id='gargbiastest_20chronabstract'  class="abstractcollapsed">
                 The University of California suspended through 2024 the requirement that applicants from California submit SAT scores, upending the major role standardized testing has played in college admissions. We study the impact of such decisions and its interplay with other intervention such as affirmative action on admitted class composition.
                 More specifically, this paper develops a theoretical framework to study the effect of requiring test scores on academic merit and diversity in college admissions. The model has a college and set of potential students. Each student an unobserved noisy skill level, and multiple observed application components and group membership. The college is Bayesian and maximizes an objective that depends on both diversity and merit. It estimates each applicant’s true skill level using the observed features, and then admits students with or without affirmative action.
                 We characterize the trade-off between the (potentially positive) informational role of standardized testing in college admissions and its (negative) exclusionary nature. Dropping test scores may exacerbate disparities by decreasing the amount of information available for each applicant, especially those from non-traditional backgrounds. However, if there are substantial barriers to testing, removing the test improves both academic merit and diversity by increasing the size of the applicant pool. The overall effect of testing depends on both the variance of the test score noise and the amount of people excluded by the test requirement.
                 Finally, using application and transcript data from the University of Texas at Austin, we demonstrate how an admissions committee could measure the trade-off in practice.
                 <br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="gargdriversurge_19typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Driver Surge Pricing</strong>
<!-- <strong>Driver Surge Pricing</strong> -->





[<a href="javascript:;"onclick=showdropinfo('gargdriversurge_19chronabstract')>abstract</a> | <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3390346">ssrn</a> | <a href="https://github.com/nikhgarg/driver_surge_rideaustin">code & data</a> | <a href="https://www.youtube.com/watch?v=JNsyikrQEHE">talk</a> | <a href="https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2021.4058">official link</a>]


<script>
  colortype("gargdriversurge_19", "article");
</script>

<br><span id="gargdriversurge_19">Nikhil Garg and Hamid Nazerzadeh</span> <br>
 Management Science<br>
  <i>(Conference version published in EC‘20.)</i><br> 

 
 <div id='gargdriversurge_19chronabstract'  class="abstractcollapsed">Ride-hailing marketplaces like Uber and Lyft use dynamic pricing, often called surge, to balance the supply of available drivers with the demand for rides. We study pricing mechanisms for such marketplaces from the perspective of drivers, presenting the theoretical foundation that has informed the design of Uber’s new additive driver surge mechanism. We present a dynamic stochastic model to capture the impact of surge pricing on driver earnings and their strategies to maximize such earnings. In this setting, some time periods (surge) are more valuable than others (non-surge), and so trips of different time lengths vary in the opportunity cost they impose on drivers. First, we show that multiplicative surge, historically the standard on ride-hailing platforms, is not incentive compatible in a dynamic setting. We then propose a structured, incentive-compatible pricing mechanism. This closed-form mechanism has a simple form and is well-approximated by Uber’s new additive surge mechanism. Finally, through both numerical analysis and real data from a ride-hailing marketplace, we show that additive surge is more approximately incentive compatible in practice than multiplicative surge, providing more stable earnings to drivers.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="liusoptionaltests21typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Test-optional Policies: Overcoming Strategic Behavior and Informational Gaps</strong>
<!-- <strong>Test-optional Policies: Overcoming Strategic Behavior and Informational Gaps</strong> -->





[<a href="javascript:;"onclick=showdropinfo('liusoptionaltests21chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2107.08922">arxiv</a>]


<script>
  colortype("liusoptionaltests21", "inproceedings");
</script>

<br><span id="liusoptionaltests21">Zhi Liu and Nikhil Garg</span> <br>
 AAAI/ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization (EAAMO‘21)<br>
 

 
 <div id='liusoptionaltests21chronabstract'  class="abstractcollapsed">
               Due to the Covid-19 pandemic, more than 500 US-based colleges and universities went “test-optional” for admissions and promised that they would not penalize applicants for not submitting test scores, part of a longer trend to rethink the role of testing in college admissions. However, it remains unclear how (and whether) a college can simultaneously use test scores for those who submit them, while not penalizing those who do not–and what that promise even means. We formalize these questions, and study how a college can overcome two challenges with optional testing: strategic applicants  (when those with low test scores can pretend to not have taken the test), and informational gaps (it has more information on those who submit a test score than those who do not). We find that colleges can indeed do so, if and only if they are able to use information on who has test access and are willing to randomize admissions.
               <br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="guovector21typecount">&nbsp;&nbsp;</span>&nbsp;<strong>The Stereotyping Problem in Collaboratively Filtered Recommender Systems</strong>
<!-- <strong>The Stereotyping Problem in Collaboratively Filtered Recommender Systems</strong> -->





[<a href="javascript:;"onclick=showdropinfo('guovector21chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/2106.12622">arxiv</a>]


<script>
  colortype("guovector21", "inproceedings");
</script>

<br><span id="guovector21">Wenshuo Guo, Karl Krauth, Michael I. Jordan, and Nikhil Garg</span> <br>
 AAAI/ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization (EAAMO‘21)<br>
 

 
 <div id='guovector21chronabstract'  class="abstractcollapsed">
               Recommender systems – and especially matrix factorization-based collaborative filtering algorithms – play a crucial role in mediating our access to online information. We show that such algorithms induce a particular kind of stereotyping: if preferences for a set of items are anti-correlated in the general user population, then those items may not be recommended together to a user, regardless of that user’s preferences and ratings history. First, we introduce a notion of joint accessibility, which measures the extent to which a set of items can jointly be accessed by users. We then study joint accessibility under the standard factorization-based collaborative filtering framework, and provide theoretical necessary and sufficient conditions when joint accessibility is violated. Moreover, we show that these conditions can easily be violated when the users are represented by a single feature vector.
               To improve joint accessibility,  we further propose an alternative modelling fix, which is designed to capture the diverse multiple interests of each user using a multi-vector representation. We conduct extensive experiments on real and simulated datasets, demonstrating the stereotyping problem with standard single-vector matrix factorization models.
               <br></div>
 

 
</p>
 

</li></ol>
    
  
    
    
    <h2> 2020 </h2>
    <ol class="bibliography"><li><p class="reallysmallbib">
<span id="caifairallocation_19typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Fair Allocation through Selective Information Acquisition</strong>
<!-- <strong>Fair Allocation through Selective Information Acquisition</strong> -->





[<a href="javascript:;"onclick=showdropinfo('caifairallocation_19chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/1911.02715">arxiv</a>]


<script>
  colortype("caifairallocation_19", "inproceedings");
</script>

<br><span id="caifairallocation_19">William Cai, Johann Gaebler, Nikhil Garg, and Sharad Goel</span> <br>
 AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society (AIES‘20)<br>
 

 
 <div id='caifairallocation_19chronabstract'  class="abstractcollapsed">Public and private institutions must often
               allocate scare resources under uncertainty.
               Banks, for example, extend credit to loan applicants based in part on their estimated likelihood of repaying a loan.
               But when the quality of information differs across candidates (e.g., if some applicants lack traditional credit histories), common lending strategies can lead to disparities across groups. Here we consider a setting in which decision makers—before allocating resources—can choose to spend some of their limited budget further screening select individuals. We present a computationally efficient algorithm for deciding whom to screen that maximizes a standard measure of social welfare.
               Intuitively, decision makers should screen candidates on the margin, for whom the additional information could plausibly alter the allocation. We formalize this idea by showing the problem can be reduced to solving a series of linear programs. Both on synthetic and real-world datasets, this strategy improves utility, illustrating the value of targeted information acquisition in such decisions. Further, when there is social value for distributing resources to groups for whom we have a priori poor information—like those without credit scores—our approach can substantially improve the allocation of limited assets.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="garg_phd_2020typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Designing Marketplaces and Civic Engagement Platforms: Learning, Incentives, and Pricing</strong>
<!-- <strong>Designing Marketplaces and Civic Engagement Platforms: Learning, Incentives, and Pricing</strong> -->





[<a href="javascript:;"onclick=showdropinfo('garg_phd_2020chronabstract')>abstract</a> | <a href="http://purl.stanford.edu/mf806mq4601">official link</a> | <a href="/files/papers/garg_dissertation_summary.pdf">summary</a> | <a href="https://www.youtube.com/watch?v=03IFmGa1ZQg">talk</a> | <a href="https://www.youtube.com/watch?v=rF5S8b80uwQ">short talk</a>]


<script>
  colortype("garg_phd_2020", "thesis");
</script>

<br><span id="garg_phd_2020">Nikhil Garg</span> <br>
 
  <i>PhD Dissertation, Stanford University<br>INFORMS George Dantzig Dissertation Award, 2020<br>ACM SIGecom dissertation award (Honorable mention), 2021</i><br> 

 
 <div id='garg_phd_2020chronabstract'  class="abstractcollapsed"> Platforms increasingly mediate interactions between people: both helping us find work and transportation, and supporting our civic society through discussion and decision-making. Principled system design requires formalizing the platform’s objective and understanding the incentives, behavioral tendencies, and capabilities of participants; in turn, the design influences participant behavior. In this dissertation, I describe work designing platforms in two domains – two-sided marketplaces and civic engagement platforms – combining both theoretical and empirical analyses of such systems. First, I consider the design of surge pricing that is incentive compatible for drivers in ride-hailing platforms. Second, I tackle rating system inflation and design on online platforms. Finally, I study the design and deployment of systems for participatory budgeting. The work in this dissertation has informed deployments at Uber, a large online labor platform, and in participatory budgeting elections across the U.S.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="ratings_2020typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Designing Informative Rating Systems: Evidence from an Online Labor Market</strong>
<!-- <strong>Designing Informative Rating Systems: Evidence from an Online Labor Market</strong> -->





[<a href="javascript:;"onclick=showdropinfo('ratings_2020chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/1810.13028">arxiv</a> | <a href="https://www.youtube.com/watch?v=dCRVyX_p4K0">talk</a> | <a href="https://pubsonline.informs.org/doi/10.1287/msom.2020.0921">official link</a>]


<script>
  colortype("ratings_2020", "article");
</script>

<br><span id="ratings_2020">Nikhil Garg and Ramesh Johari</span> <br>
 Manufacturing & Service Operations Management<br>
  <i><font color="red">Media</font>: <a href="https://www.nytimes.com/2019/05/25/opinion/sunday/five-star-customer-reviews.html">New York Times</a>, <a href="https://engineering.stanford.edu/magazine/article/story-rated-five-stars">Stanford Engineering magazine</a>.<br>M&SOM student paper award (2nd place), 2020<br>(Conference version published in EC‘20.)</i><br> 

 
 <div id='ratings_2020chronabstract'  class="abstractcollapsed">Platforms critically rely on rating systems to learn the quality of market participants. In practice, however, these ratings are often highly inflated, drastically reducing the signal available to distinguish quality.  We consider two questions: First, can rating systems better discriminate quality by altering the meaning and relative importance of the levels in the rating system? And second, if so, how should the platform optimize these choices in the design of the rating system?

               We first analyze the results of a randomized controlled trial on an online labor market in which an additional question was added to the feedback form. Between treatment conditions, we vary the question phrasing and answer choices.  We further run an experiment on Amazon Mechanical Turk with similar structure, to confirm the labor market findings. Our tests reveal that current inflationary norms can in fact be countered by re-anchoring the meaning of the levels of the rating system. In particular, scales that are positive-skewed and provide specific interpretations for what each label means yield rating distributions that are much more informative about quality.

               Second, we develop a theoretical framework to optimize the design of a rating system by choosing answer labels and their numeric interpretations in a manner that maximizes the rate of convergence to the true underlying quality distribution. Finally, we run simulations with an empirically calibrated model and use these to study the implications for optimal rating system design. Our simulations demonstrate that our modeling and optimization approach can substantially improve the quality of information obtained over baseline designs.


               Overall, our study illustrates that rating systems that are informative in practice can be designed, and demonstrates how to design them in a principled manner.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="marketspublicgoods_2020typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Markets for Public Decision-making</strong>
<!-- <strong>Markets for Public Decision-making</strong> -->





[<a href="javascript:;"onclick=showdropinfo('marketspublicgoods_2020chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/1807.10836">arxiv</a> | <a href="https://rdcu.be/caZFU">official link</a>]


<script>
  colortype("marketspublicgoods_2020", "article");
</script>

<br><span id="marketspublicgoods_2020">Nikhil Garg, Ashish Goel, and Ben Plaut</span> <br>
 Social Choice and Welfare<br>
  <i>(Conference version published in WINE‘18.)</i><br> 

 
 <div id='marketspublicgoods_2020chronabstract'  class="abstractcollapsed">A public decision-making problem consists of a set of issues, each with multiple possible alternatives, and a set of competing agents, each with a preferred alternative for each issue. We study adaptations of market economies to this setting, focusing on binary issues. Issues have prices, and each agent is endowed with artificial currency that she can use to purchase probability for her preferred alternatives (we allow randomized outcomes). We first show that when each issue has a single price that is common to all agents, market equilibria can be arbitrarily bad. This negative result motivates a different approach. We present a novel technique called "pairwise issue expansion", which transforms any public decision-making instance into an equivalent Fisher market, the simplest type of private goods market. This is done by expanding each issue into many goods: one for each pair of agents who disagree on that issue. We show that the equilibrium prices in the constructed Fisher market yield a "pairwise pricing equilibrium" in the original public decision-making problem which maximizes Nash welfare. More broadly, pairwise issue expansion uncovers a powerful connection between the public decision-making and private goods settings; this immediately yields several interesting results about public decisions markets, and furthers the hope that we will be able to find a simple iterative voting protocol that leads to near-optimum decisions.<br></div>
 

 
</p>
 

</li></ol>
    
  
    
    
    <h2> 2019 </h2>
    <ol class="bibliography"><li><p class="reallysmallbib">
<span id="garg_iterative_2018typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Iterative Local Voting for Collective Decision-making in Continuous Spaces</strong>
<!-- <strong>Iterative Local Voting for Collective Decision-making in Continuous Spaces</strong> -->





[<a href="javascript:;"onclick=showdropinfo('garg_iterative_2018chronabstract')>abstract</a> | <a href="javascript:;" onclick=showdropinfo('garg_iterative_2018chrondemo')>demo</a> | <a href="https://www.jair.org/index.php/jair/article/view/11358">official link</a>]


<script>
  colortype("garg_iterative_2018", "article");
</script>

<br><span id="garg_iterative_2018">Nikhil Garg, Vijay Kamble, Ashish Goel, David Marn, and Kamesh Munagala</span> <br>
 Journal of Artificial Intelligence Research (JAIR)<br>
  <i>(Conference version published in WWW‘17.)</i><br> 

 
 <div id='garg_iterative_2018chronabstract'  class="abstractcollapsed">Many societal decision problems lie in high-dimensional continuous spaces not amenable to the voting techniques common for their discrete or single-dimensional counterparts. These problems are typically discretized before running an election or decided upon through negotiation by representatives. We propose a algorithm called Iterative Local Voting for collective decision-making in this setting. In this algorithm, voters are sequentially sampled and asked to modify a candidate solution within some local neighborhood of its current value, as defined by a ball in some chosen norm, with the size of the ball shrinking at a specified rate.

              We first prove the convergence of this algorithm under appropriate choices of neighborhoods to Pareto optimal solutions with desirable fairness properties in certain natural settings: when the voters’ utilities can be expressed in terms of some form of distance from their ideal solution, and when these utilities are additively decomposable across dimensions. In many of these cases, we obtain convergence to the societal welfare maximizing solution.

              We then describe an experiment in which we test our algorithm for the decision of the U.S. Federal Budget on Mechanical Turk with over 2,000 workers, employing neighborhoods defined by various L-Norm balls. We make several observations that inform future implementations of such a procedure.<br></div>
 

 
 <div id='garg_iterative_2018chrondemo'  class="abstractcollapsed">We have a demo of our Mechanical Turk experiment available live <a href="http://54.183.140.235/">here</a>. It can be used as follows:
<ol>
  <li>If the URL is entered without any parameters, it uses the current radius (based on previous uses of the demo, going down by $1/N$) and uses the $\mathcal{L}^2$ mechanism.</li>
  <li>To set the mechanism, navigate to <i>http://54.183.140.235/mechanism/[option]/</i>, where instead of <i>[option]</i> use either, <i>l1</i>, <i>l2</i>, <i>linf</i>, or <i>full</i>, for the respective mechanisms.</li>
  <li>To set the radius, navigate to <i>http://54.183.140.235/mechanism/[number]/</i>, where any integer can be entered instead of <i>[number]</i>. This option resets the starting radius for the specific mechanism, which will go down by $1/N$ in subsequent accesses.</li>
  <li>To set both the mechanism and the radius, navigate to <i>http://54.183.140.235/radius/[number]/mechanism/[option]/</i>, with the above options.</li>
</lo>
</div>
 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="binratingcomparisons_2018typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Designing Optimal Binary Rating Systems</strong>
<!-- <strong>Designing Optimal Binary Rating Systems</strong> -->





[<a href="javascript:;"onclick=showdropinfo('binratingcomparisons_2018chronabstract')>abstract</a> | <a href="http://proceedings.mlr.press/v89/garg19a">official link</a>]


<script>
  colortype("binratingcomparisons_2018", "inproceedings");
</script>

<br><span id="binratingcomparisons_2018">Nikhil Garg and Ramesh Johari</span> <br>
 International Conference on Artificial Intelligence and Statistics (AISTATS‘19)<br>
 

 
 <div id='binratingcomparisons_2018chronabstract'  class="abstractcollapsed">Modern online platforms rely on effective rating systems to learn about items.  We consider the optimal design of rating systems that collect binary feedback after transactions.  We make three contributions.  First, we formalize the performance of a rating system as the speed with which it recovers the true underlying ranking on items (in a large deviations sense), accounting for both items’ underlying match rates and the platform’s preferences.  Second, we provide an efficient algorithm to compute the binary feedback system that yields the highest such performance.  Finally, we show how this theoretical perspective can be used to empirically design an implementable, approximately optimal rating system, and validate our approach using real-world experimental data collected on Amazon Mechanical Turk.
               <br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="demszky_analyzing_2019typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Analyzing Polarization in Social Media: Method and Application to Tweets on 21 Mass Shootings</strong>
<!-- <strong>Analyzing Polarization in Social Media: Method and Application to Tweets on 21 Mass Shootings</strong> -->





[<a href="javascript:;"onclick=showdropinfo('demszky_analyzing_2019chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/1904.01596">arxiv</a> | <a href="https://github.com/ddemszky/framing-twitter">code & data</a>]


<script>
  colortype("demszky_analyzing_2019", "inproceedings");
</script>

<br><span id="demszky_analyzing_2019">Dorottya Demszky, Nikhil Garg, Rob Voigt, James Zou, Jesse Shapiro, Matthew Gentzkow, and Dan Jurafsky</span> <br>
 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL‘19)<br>
  <i><font color="red">Media</font>: <a href="https://www.washingtonpost.com/politics/2019/06/26/democrats-focus-more-victims-republicans-perpetrators-after-mass-shootings-study-finds/?noredirect=on&utm_term=.43380fd237c4">Washington Post</a>, <a href="https://news.stanford.edu/2019/06/25/analyzing-tweets-republicans-democrats/">Stanford News</a>.</i><br> 

 
 <div id='demszky_analyzing_2019chronabstract'  class="abstractcollapsed">We provide an NLP framework to uncover four linguistic dimensions of political polarization in social media: topic choice, framing, affect and illocutionary force. We quantify these aspects with existing lexical methods, and propose clustering of tweet embeddings as a means to identify salient topics for analysis across events; human evaluations show that our approach generates more cohesive topics than traditional LDA-based models. We apply our methods to study 4.4M tweets on 21 mass shootings. We provide evidence that the discussion of these events is highly polarized politically and that this polarization is primarily driven by partisan differences in framing rather than topic choice. We identify framing devices, such as grounding and the contrasting use of the terms "terrorist" and "crazy", that contribute to polarization. Results pertaining to topic choice, affect and illocutionary force suggest that Republicans focus more on the shooter and event-specific facts (news) while Democrats focus more on the victims and call for policy changes. Our work contributes to a deeper understanding of the way group divisions manifest in language and to computational methods for studying them.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="gargvotermultiwinner_19typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Who is in Your Top Three? Optimizing Learning in Elections with Many Candidates</strong>
<!-- <strong>Who is in Your Top Three? Optimizing Learning in Elections with Many Candidates</strong> -->





[<a href="javascript:;"onclick=showdropinfo('gargvotermultiwinner_19chronabstract')>abstract</a> | <a href="https://arxiv.org/abs/1906.08160">arxiv</a>]


<script>
  colortype("gargvotermultiwinner_19", "inproceedings");
</script>

<br><span id="gargvotermultiwinner_19">Nikhil Garg, Lodewijk Gelauff, Sukolsak Sakshuwong, and Ashish Goel</span> <br>
 AAAI Conference on Human Computation and Crowdsourcing (HCOMP‘19)<br>
 

 
 <div id='gargvotermultiwinner_19chronabstract'  class="abstractcollapsed">Elections and opinion polls often have many candidates, with the aim to either rank the candidates or identify a small set of winners according to voters’ preferences. In practice, voters do not provide a full ranking; instead, each voter provides their favorite K candidates, potentially in ranked order. The election organizer must choose K and an aggregation rule.

               We provide a theoretical framework to make these choices. Each K-Approval or K-partial ranking mechanism (with a corresponding positional scoring rule) induces a learning rate for the speed at which the election correctly recovers the asymptotic outcome. Given the voter choice distribution, the election planner can thus identify the rate optimal mechanism. Earlier work in this area provides coarse order-of-magnitude guaranties which are not sufficient to make such choices.
               Our framework further resolves questions of when randomizing between multiple mechanisms may improve learning, for arbitrary voter noise models.

               Finally, we use data from 5 large participatory budgeting elections that we organized across several US cities, along with other ranking data, to demonstrate the utility of our methods. In particular, we find that historically such elections have set K too low and that picking the right mechanism can be the difference between identifying the correct winner with only a 80% probability or a 99.9% probability after 500 voters.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="fishkindeliberation_19typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Deliberative Democracy with the Online Deliberation Platform</strong>
<!-- <strong>Deliberative Democracy with the Online Deliberation Platform</strong> -->








<script>
  colortype("fishkindeliberation_19", "techreport");
</script>

<br><span id="fishkindeliberation_19">James Fishkin, Nikhil Garg, Lodewijk Gelauff, Ashish Goel, Kamesh Munagala, Sukolsak Sakshuwong, Alice Siu, and Sravya Yandamuri</span> <br>
 AAAI Conference on Human Computation and Crowdsourcing Demo Track<br>
 

 

 
</p>
 

</li></ol>
    
  
    
    
    <h2> 2018 </h2>
    <ol class="bibliography"><li><p class="reallysmallbib">
<span id="garg_word_2018typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes</strong>
<!-- <strong>Word Embeddings Quantify 100 Years of Gender and Ethnic Stereotypes</strong> -->





[<a href="javascript:;"onclick=showdropinfo('garg_word_2018chronabstract')>abstract</a> | <a href="https://doi.org/10.1073/pnas.1720347115">official link</a> | <a href="https://github.com/nikhgarg/EmbeddingDynamicStereotypes">code & data</a> | <a href="https://www.youtube.com/watch?v=boxV8Od4jqQ&list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9&index=13">talk</a>]


<script>
  colortype("garg_word_2018", "article");
</script>

<br><span id="garg_word_2018">Nikhil Garg, Londa Schiebinger, Dan Jurafsky, and James Zou</span> <br>
 Proceedings of the National Academy of Sciences (PNAS)<br>
  <i><font color="red">Media</font>: <a href="https://news.stanford.edu/2018/04/03/algorithms-reveal-changes-stereotypes/">Stanford News</a> <a href="https://ee.stanford.edu/news/research-news/04-05-2018/gargnikhil-uses-machine-learning-measure-stereotypes ">(and EE department)</a>, <a href="https://www.sciencemag.org/news/2018/04/artificial-intelligence-reveals-how-us-stereotypes-about-women-and-minorities-have ">Science Magazine</a>, <a href="https://www.smithsonianmag.com ">Smithsonian Magazine</a> <a href="/img/projects/smithsonianpicture.jpg">(in print)</a>, <a href="https://www.weforum.org/agenda/2018/04/algorithms-trace-how-stereotypes-have-changed/">The World Economic Forum</a>, <a href="https://www.futurity.org/algorithm-word-embeddings-stereotypes-bias-1722542/">Futurity</a>, <a href="https://pnas.altmetric.com/details/29305270/news">etc</a>.</i><br> 

 
 <div id='garg_word_2018chronabstract'  class="abstractcollapsed">Word embeddings are a powerful machine-learning framework that represents each English word by a vector. The geometric relationship between these vectors captures meaningful semantic relationships between the corresponding words. In this paper, we develop a framework to demonstrate how the temporal dynamics of the embedding helps to quantify changes in stereotypes and attitudes toward women and ethnic minorities in the 20th and 21st centuries in the United States. We integrate word embeddings trained on 100 y of text data with the US Census to show that changes in the embedding track closely with demographic and occupation shifts over time. The embedding captures societal shifts - e.g., the women’s movement in the 1960s and Asian immigration into the United States - and also illuminates how specific adjectives and occupations became more closely associated with certain populations over time. Our framework for temporal analysis of word embedding opens up a fruitful intersection between machine learning and quantitative social science.<br></div>
 

 
</p>
 

</li></ol>
    
  
    
    
  
    
    
  
    
    
    <h2> 2015 </h2>
    <ol class="bibliography"><li><p class="reallysmallbib">
<span id="lewandowski_use_2015typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Use of Electroencephalography and Galvanic Skin Response in the Prediction of an Attentive Cognitive State</strong>
<!-- <strong>Use of Electroencephalography and Galvanic Skin Response in the Prediction of an Attentive Cognitive State</strong> -->





[<a href="javascript:;"onclick=showdropinfo('lewandowski_use_2015chronabstract')>abstract</a> | <a href="/files/pdfs/HHPRSummitAbstract.pdf">pdf</a>]


<script>
  colortype("lewandowski_use_2015", "techreport");
</script>

<br><span id="lewandowski_use_2015">Beth Lewandowski, Kier Fortier, Nikhil Garg, Victor Rielly, Jeff Mackey, Tristan Hearn, Angela Harrivel, and Bradford Fenton</span> <br>
 Health and Human Performance Research Summit, Dayton, CO<br>
 

 
 <div id='lewandowski_use_2015chronabstract'  class="abstractcollapsed">As part of an effort aimed at improving aviation safety, the Crew State Monitoring
               Element of the NASA Vehicle Systems Safety Technologies Project is developing a monitoring
               system capable of detecting cognitive states that may be associated with unsafe piloting
               conditions. The long term goal is a real-time, integrated system, that uses multiple physiological
               sensing modalities to detect multiple cognitive states with high accuracy, which can be used to
               help optimize human performance. Prior to realizing an integrated system, individual sensing
               modalities are being investigated, including the use of electroencephalographic (EEG) and
               galvanic skin response (GSR) signals, in the determination of an attentive or inattentive state.
               EEG and GSR data are collected during periods of rest and as subjects perform
               psychological tests including the psychomotor vigilance test, the Mackwork clock test and the
               attention network test. Subjects also perform tasks designed to simulate piloting tasks within the
               NASA multi-attribute task battery (MATB-II) program. The signals are filtered, the artifacts are
               rejected and the power spectral density (PSD) of the signals are found. Comparisons of the PSD
               between the rest and test blocks are made, along with the change in PSD over the time course of
               the blocks. Future work includes the collection of heart rate data and the investigation of heart
               rate variability as an additional measure to use in the prediction of attentive state, as well as the
               investigation of additional EEG signal processing methods such as source localization, multi-
               scale entropy and coherence measures. Preliminary results will be presented to highlight the
               methods used and to discuss our hypotheses.
               The challenges associated with realizing a real-time, accurate, multi-modal, cognitive
               state monitoring system are numerous. A discussion of some of the challenges will be provided,
               including real-time artifact rejection methods, quantification of inter- and intra-subject
               variability, determination of what information within the signals provides the best measurement
               of attention and determination of how information from the different modalities can be integrated
               to improve the overall accuracy of the system.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="garg_downlink_2015typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Downlink and Uplink User Association in Dense Next-Generation Wireless Networks</strong>
<!-- <strong>Downlink and Uplink User Association in Dense Next-Generation Wireless Networks</strong> -->





[<a href="javascript:;"onclick=showdropinfo('garg_downlink_2015chronabstract')>abstract</a> | <a href="http://repositories.lib.utexas.edu/handle/2152/30074">official link</a>]


<script>
  colortype("garg_downlink_2015", "thesis");
</script>

<br><span id="garg_downlink_2015">Nikhil Garg</span> <br>
 
  <i>Bachelors Thesis, University of Texas at Austin.</i><br> 

 
 <div id='garg_downlink_2015chronabstract'  class="abstractcollapsed">5G, the next-generation cellular network, must serve an aggregate data rate of
              1000 times that of current 4G networks while reducing data latency by a factor of ten. To meet these requirements, 5G networks will be far denser than existing networks, and small cells (femtocells and picocells) will augment network capacity. However, dense networks raise questions regarding interference, user association, and handoff between base stations. Where recent papers have demonstrated that interference from small cells will not be prohibitive under multi-slope path loss models, this thesis describes how the use of different path loss models affects the design of such dense, multi-tier networks. This thesis concludes that the gains realized by downlink biasing and uplink/downlink decoupling are strongly dependent on the path loss model assumed and the density differential between base station tiers. Furthermore, this thesis argues that the gains from uplink/downlink decoupling are reduced by a factor of 50% when optimal biasing for the downlink is used.<br></div>
 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="garg_fair_2015typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Fair Use and Innovation in Unlicensed Wireless Spectrum: LTE unlicensed and Wi-Fi in the 5 GHz unlicensed band</strong>
<!-- <strong>Fair Use and Innovation in Unlicensed Wireless Spectrum: LTE unlicensed and Wi-Fi in the 5 GHz unlicensed band</strong> -->





[<a href="/files/pdfs/Garg_Fair Use and Innovation in Unlicensed Wireless Spectrum.pdf">pdf</a>]


<script>
  colortype("garg_fair_2015", "techreport");
</script>

<br><span id="garg_fair_2015">Nikhil Garg</span> <br>
 IEEE-USA Journal of Technology and Public Policy<br>
 

 

 
</p>
 

</li>
<li><p class="reallysmallbib">
<span id="garg_impact_2015typecount">&nbsp;&nbsp;</span>&nbsp;<strong>Impact of Dual Slope Path Loss on User Association in HetNets</strong>
<!-- <strong>Impact of Dual Slope Path Loss on User Association in HetNets</strong> -->





[<a href="javascript:;"onclick=showdropinfo('garg_impact_2015chronabstract')>abstract</a> | <a href="https://doi.org/10.1109/GLOCOMW.2015.7413977">official link</a>]


<script>
  colortype("garg_impact_2015", "inproceedings");
</script>

<br><span id="garg_impact_2015">Nikhil Garg, Sarabjot Singh, and Jeffrey Andrews</span> <br>
 IEEE Globecom Workshop<br>
 

 
 <div id='garg_impact_2015chronabstract'  class="abstractcollapsed">Intelligent load balancing is essential to fully realize the benefits of dense heterogeneous networks. Current techniques have largely been studied with single slope path loss models, though multi-slope models are known to more closely match real deployments. This paper develops insight into the performance of biasing and uplink/downlink decoupling for user association in HetNets with dual slope path loss models. It is shown that dual slope path loss models change the tradeoffs inherent in biasing and reduce gains from both biasing and uplink/downlink decoupling. The results show that with the dual slope path loss models, the bias maximizing the median rate is not optimal for other users, e.g., edge users. Furthermore, optimal downlink biasing is shown to realize most of the gains from downlink-uplink decoupling. Moreover, the user association gains in dense networks are observed to be quite sensitive to the path loss exponent beyond the critical distance in a dual slope model.<br></div>
 

 
</p>
 

</li></ol>
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
</div>

<script>
  function openPapers(evt, buttonname) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
      tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
      if (!tablinks[i].id.indexOf(buttonname)>-1){
        tablinks[i].className = tablinks[i].className.replace(" active", "");
      }
    }
    // document.getElementById(buttonname).className = "tablinks active"
    document.getElementById(buttonname).style.display = "block";
    elembutton = document.getElementById(buttonname + 'Button')
    if (elembutton.className && !elembutton.className.indexOf("active")>-1){
      elembutton.className += " active";
    }
  }
  window.onload=openPapers(event, 'PaperType');
</script>

</div>

    </div>
    </main>

    <footer role="contentinfo">
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-53767206-2', 'auto');
  ga('send', 'pageview');

</script>
</footer>
</body>

</html>
